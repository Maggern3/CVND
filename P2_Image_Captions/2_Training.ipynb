{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** The CNN part uses the resnet50 architecture(pre-trained) which gives good performance and speed. It's very deep, 50 layers, which is pretty cool and it avoids the vanishing gradients problem by utilizing resnet blocks which are shortcuts for the optimizer to take when it's pushing weight changes far down the network. The RNN part uses an LSTM.\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** ResNet expects input of 3x224x224 so I think cropping it to that size is the way to go. I've seen previsouly that transformations like RandomHorizontalFlip and RandomCrop can actually increase the performance of the network so I left them as is.\n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** I didn't really, I don't understand why you would perform a selection like the one above, when you have already frozen the parameters of the pre-trained model?\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** I choose Adam because it uses momentum to avoid getting stuck in local minima and also performs some numerical stability operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.2.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 443/414113 [00:00<01:33, 4429.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 810/414113 [00:00<01:39, 4167.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.87s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1249/414113 [00:00<01:37, 4229.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1523/414113 [00:01<06:40, 1030.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1957/414113 [00:01<05:08, 1336.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2383/414113 [00:01<04:04, 1682.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2809/414113 [00:01<03:20, 2054.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3243/414113 [00:01<02:48, 2439.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3680/414113 [00:01<02:25, 2812.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4114/414113 [00:01<02:10, 3142.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4561/414113 [00:01<01:58, 3448.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5014/414113 [00:01<01:50, 3713.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 5459/414113 [00:01<01:44, 3905.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 5906/414113 [00:02<01:40, 4057.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6347/414113 [00:02<01:38, 4156.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6793/414113 [00:02<01:36, 4241.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7237/414113 [00:02<01:34, 4297.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7679/414113 [00:02<01:34, 4286.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8132/414113 [00:02<01:33, 4353.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8577/414113 [00:02<01:32, 4381.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9020/414113 [00:02<01:32, 4381.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9462/414113 [00:02<01:32, 4384.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9903/414113 [00:02<01:32, 4368.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10342/414113 [00:03<01:32, 4356.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10782/414113 [00:03<01:32, 4366.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11220/414113 [00:03<01:32, 4367.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11659/414113 [00:03<01:32, 4371.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12097/414113 [00:03<01:32, 4364.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12534/414113 [00:03<01:32, 4356.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12971/414113 [00:03<01:32, 4359.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13420/414113 [00:03<01:31, 4396.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13860/414113 [00:03<01:31, 4385.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14305/414113 [00:03<01:30, 4403.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 14746/414113 [00:04<01:34, 4235.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 15172/414113 [00:04<01:34, 4220.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 15598/414113 [00:04<01:34, 4230.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16032/414113 [00:04<01:33, 4262.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16472/414113 [00:04<01:32, 4302.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16914/414113 [00:04<01:31, 4334.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17348/414113 [00:04<01:31, 4325.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17789/414113 [00:04<01:31, 4349.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 18225/414113 [00:04<01:31, 4336.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 18660/414113 [00:04<01:31, 4338.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19095/414113 [00:05<01:31, 4340.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19534/414113 [00:05<01:30, 4355.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19970/414113 [00:05<01:30, 4344.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 20406/414113 [00:05<01:30, 4347.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 20847/414113 [00:05<01:30, 4364.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21284/414113 [00:05<01:29, 4366.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21727/414113 [00:05<01:29, 4384.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 22166/414113 [00:05<01:29, 4372.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 22610/414113 [00:05<01:29, 4391.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23056/414113 [00:05<01:28, 4410.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23500/414113 [00:06<01:28, 4415.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23946/414113 [00:06<01:28, 4428.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 24389/414113 [00:06<01:28, 4422.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 24832/414113 [00:06<01:28, 4412.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 25276/414113 [00:06<01:27, 4419.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 25723/414113 [00:06<01:27, 4432.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 26171/414113 [00:06<01:27, 4446.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 26616/414113 [00:06<01:27, 4406.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 27057/414113 [00:06<01:28, 4376.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 27495/414113 [00:06<01:32, 4174.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 27929/414113 [00:07<01:31, 4222.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 28367/414113 [00:07<01:30, 4266.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 28800/414113 [00:07<01:29, 4284.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 29234/414113 [00:07<01:29, 4299.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 29677/414113 [00:07<01:28, 4335.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30117/414113 [00:07<01:28, 4352.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30554/414113 [00:07<01:28, 4355.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 31005/414113 [00:07<01:27, 4398.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 31446/414113 [00:07<01:26, 4399.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 31888/414113 [00:07<01:26, 4403.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 32330/414113 [00:08<01:26, 4404.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 32771/414113 [00:08<01:27, 4372.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 33214/414113 [00:08<01:26, 4387.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 33653/414113 [00:08<01:27, 4366.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34090/414113 [00:08<01:27, 4336.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34526/414113 [00:08<01:27, 4341.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34961/414113 [00:08<01:28, 4285.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 35390/414113 [00:08<01:28, 4282.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 35819/414113 [00:08<01:29, 4227.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 36247/414113 [00:09<01:29, 4241.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 36688/414113 [00:09<01:28, 4288.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 37140/414113 [00:09<01:26, 4353.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 37581/414113 [00:09<01:26, 4368.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38034/414113 [00:09<01:25, 4414.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38476/414113 [00:09<01:26, 4318.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38917/414113 [00:09<01:26, 4343.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 39353/414113 [00:09<01:26, 4347.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 39802/414113 [00:09<01:25, 4387.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 40242/414113 [00:09<01:25, 4380.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 40681/414113 [00:10<01:25, 4380.52it/s]\n",
      "\u001b[A\u001b[A\n",
      " 10%|▉         | 41120/414113 [00:10<01:25, 4371.70it/s]\u001b[A\n",
      " 10%|█         | 41577/414113 [00:10<01:24, 4428.48it/s]\u001b[A\n",
      " 10%|█         | 42021/414113 [00:10<01:24, 4416.55it/s]\u001b[A\n",
      " 10%|█         | 42463/414113 [00:10<01:24, 4403.00it/s]\u001b[A\n",
      " 10%|█         | 42914/414113 [00:10<01:23, 4433.63it/s]\u001b[A\n",
      " 10%|█         | 43373/414113 [00:10<01:22, 4477.57it/s]\u001b[A\n",
      " 11%|█         | 43821/414113 [00:10<01:23, 4425.46it/s]\u001b[A\n",
      " 11%|█         | 44264/414113 [00:10<01:23, 4421.52it/s]\u001b[A\n",
      " 11%|█         | 44707/414113 [00:10<01:24, 4383.85it/s]\u001b[A\n",
      " 11%|█         | 45146/414113 [00:11<01:24, 4359.26it/s]\u001b[A\n",
      " 11%|█         | 45583/414113 [00:11<01:24, 4354.37it/s]\u001b[A\n",
      " 11%|█         | 46020/414113 [00:11<01:24, 4358.97it/s]\u001b[A\n",
      " 11%|█         | 46466/414113 [00:11<01:23, 4386.60it/s]\u001b[A\n",
      " 11%|█▏        | 46905/414113 [00:11<01:24, 4334.83it/s]\u001b[A\n",
      " 11%|█▏        | 47352/414113 [00:11<01:23, 4372.71it/s]\u001b[A\n",
      " 12%|█▏        | 47790/414113 [00:11<01:23, 4369.78it/s]\u001b[A\n",
      " 12%|█▏        | 48233/414113 [00:11<01:23, 4387.21it/s]\u001b[A\n",
      " 12%|█▏        | 48676/414113 [00:11<01:23, 4399.86it/s]\u001b[A\n",
      " 12%|█▏        | 49117/414113 [00:11<01:22, 4402.58it/s]\u001b[A\n",
      " 12%|█▏        | 49558/414113 [00:12<01:23, 4376.46it/s]\u001b[A\n",
      " 12%|█▏        | 49996/414113 [00:12<01:23, 4372.61it/s]\u001b[A\n",
      " 12%|█▏        | 50434/414113 [00:12<01:23, 4342.98it/s]\u001b[A\n",
      " 12%|█▏        | 50871/414113 [00:12<01:23, 4348.28it/s]\u001b[A\n",
      " 12%|█▏        | 51306/414113 [00:12<01:24, 4290.11it/s]\u001b[A\n",
      " 12%|█▏        | 51738/414113 [00:12<01:24, 4297.13it/s]\u001b[A\n",
      " 13%|█▎        | 52174/414113 [00:12<01:23, 4314.99it/s]\u001b[A\n",
      " 13%|█▎        | 52608/414113 [00:12<01:23, 4319.15it/s]\u001b[A\n",
      " 13%|█▎        | 53041/414113 [00:12<01:23, 4308.86it/s]\u001b[A\n",
      " 13%|█▎        | 53484/414113 [00:12<01:23, 4342.73it/s]\u001b[A\n",
      " 13%|█▎        | 53922/414113 [00:13<01:22, 4353.65it/s]\u001b[A\n",
      " 13%|█▎        | 54381/414113 [00:13<01:21, 4419.81it/s]\u001b[A\n",
      " 13%|█▎        | 54837/414113 [00:13<01:20, 4458.87it/s]\u001b[A\n",
      " 13%|█▎        | 55296/414113 [00:13<01:19, 4495.33it/s]\u001b[A\n",
      " 13%|█▎        | 55746/414113 [00:13<01:19, 4495.76it/s]\u001b[A\n",
      " 14%|█▎        | 56196/414113 [00:13<01:19, 4486.21it/s]\u001b[A\n",
      " 14%|█▎        | 56645/414113 [00:13<01:20, 4439.95it/s]\u001b[A\n",
      " 14%|█▍        | 57090/414113 [00:13<01:20, 4412.34it/s]\u001b[A\n",
      " 14%|█▍        | 57532/414113 [00:13<01:21, 4385.56it/s]\u001b[A\n",
      " 14%|█▍        | 57971/414113 [00:13<01:21, 4374.69it/s]\u001b[A\n",
      " 14%|█▍        | 58409/414113 [00:14<01:21, 4366.41it/s]\u001b[A\n",
      " 14%|█▍        | 58846/414113 [00:14<01:21, 4363.57it/s]\u001b[A\n",
      " 14%|█▍        | 59299/414113 [00:14<01:20, 4410.51it/s]\u001b[A\n",
      " 14%|█▍        | 59746/414113 [00:14<01:20, 4425.99it/s]\u001b[A\n",
      " 15%|█▍        | 60195/414113 [00:14<01:19, 4443.81it/s]\u001b[A\n",
      " 15%|█▍        | 60642/414113 [00:14<01:19, 4449.57it/s]\u001b[A\n",
      " 15%|█▍        | 61088/414113 [00:14<01:19, 4446.35it/s]\u001b[A\n",
      " 15%|█▍        | 61533/414113 [00:14<01:19, 4445.46it/s]\u001b[A\n",
      " 15%|█▍        | 61979/414113 [00:14<01:19, 4447.69it/s]\u001b[A\n",
      " 15%|█▌        | 62424/414113 [00:14<01:19, 4428.09it/s]\u001b[A\n",
      " 15%|█▌        | 62887/414113 [00:15<01:18, 4484.45it/s]\u001b[A\n",
      " 15%|█▌        | 63342/414113 [00:15<01:17, 4501.83it/s]\u001b[A\n",
      " 15%|█▌        | 63819/414113 [00:15<01:16, 4578.56it/s]\u001b[A\n",
      " 16%|█▌        | 64278/414113 [00:15<01:18, 4466.90it/s]\u001b[A\n",
      " 16%|█▌        | 64726/414113 [00:15<01:19, 4380.97it/s]\u001b[A\n",
      " 16%|█▌        | 65167/414113 [00:15<01:19, 4388.86it/s]\u001b[A\n",
      " 16%|█▌        | 65607/414113 [00:15<01:19, 4386.95it/s]\u001b[A\n",
      " 16%|█▌        | 66061/414113 [00:15<01:18, 4428.69it/s]\u001b[A\n",
      " 16%|█▌        | 66505/414113 [00:15<01:19, 4377.87it/s]\u001b[A\n",
      " 16%|█▌        | 66944/414113 [00:15<01:19, 4371.91it/s]\u001b[A\n",
      " 16%|█▋        | 67382/414113 [00:16<01:20, 4316.71it/s]\u001b[A\n",
      " 16%|█▋        | 67817/414113 [00:16<01:20, 4326.03it/s]\u001b[A\n",
      " 16%|█▋        | 68250/414113 [00:16<01:22, 4200.06it/s]\u001b[A\n",
      " 17%|█▋        | 68695/414113 [00:16<01:20, 4268.92it/s]\u001b[A\n",
      " 17%|█▋        | 69147/414113 [00:16<01:19, 4338.92it/s]\u001b[A\n",
      " 17%|█▋        | 69591/414113 [00:16<01:18, 4368.01it/s]\u001b[A\n",
      " 17%|█▋        | 70032/414113 [00:16<01:18, 4379.32it/s]\u001b[A\n",
      " 17%|█▋        | 70471/414113 [00:16<01:18, 4375.61it/s]\u001b[A\n",
      " 17%|█▋        | 70909/414113 [00:16<01:19, 4312.04it/s]\u001b[A\n",
      " 17%|█▋        | 71348/414113 [00:17<01:19, 4333.14it/s]\u001b[A\n",
      " 17%|█▋        | 71794/414113 [00:17<01:18, 4368.73it/s]\u001b[A\n",
      " 17%|█▋        | 72237/414113 [00:17<01:17, 4384.17it/s]\u001b[A\n",
      " 18%|█▊        | 72690/414113 [00:17<01:17, 4426.66it/s]\u001b[A\n",
      " 18%|█▊        | 73139/414113 [00:17<01:16, 4444.68it/s]\u001b[A\n",
      " 18%|█▊        | 73584/414113 [00:17<01:17, 4422.34it/s]\u001b[A\n",
      " 18%|█▊        | 74027/414113 [00:17<01:17, 4413.70it/s]\u001b[A\n",
      " 18%|█▊        | 74469/414113 [00:17<01:18, 4351.20it/s]\u001b[A\n",
      " 18%|█▊        | 74905/414113 [00:17<01:18, 4347.05it/s]\u001b[A\n",
      " 18%|█▊        | 75342/414113 [00:17<01:17, 4351.26it/s]\u001b[A\n",
      " 18%|█▊        | 75778/414113 [00:18<01:17, 4350.73it/s]\u001b[A\n",
      " 18%|█▊        | 76214/414113 [00:18<01:18, 4311.76it/s]\u001b[A\n",
      " 19%|█▊        | 76646/414113 [00:18<01:18, 4293.70it/s]\u001b[A\n",
      " 19%|█▊        | 77090/414113 [00:18<01:17, 4333.55it/s]\u001b[A\n",
      " 19%|█▊        | 77524/414113 [00:18<01:17, 4331.64it/s]\u001b[A\n",
      " 19%|█▉        | 77958/414113 [00:18<01:17, 4320.59it/s]\u001b[A\n",
      " 19%|█▉        | 78394/414113 [00:18<01:17, 4330.28it/s]\u001b[A\n",
      " 19%|█▉        | 78828/414113 [00:18<01:17, 4329.97it/s]\u001b[A\n",
      " 19%|█▉        | 79262/414113 [00:18<01:17, 4319.63it/s]\u001b[A\n",
      " 19%|█▉        | 79695/414113 [00:18<01:17, 4314.14it/s]\u001b[A\n",
      " 19%|█▉        | 80127/414113 [00:19<01:17, 4289.92it/s]\u001b[A\n",
      " 19%|█▉        | 80557/414113 [00:19<01:18, 4270.24it/s]\u001b[A\n",
      " 20%|█▉        | 81014/414113 [00:19<01:16, 4353.99it/s]\u001b[A\n",
      " 20%|█▉        | 81469/414113 [00:19<01:15, 4409.51it/s]\u001b[A\n",
      " 20%|█▉        | 81911/414113 [00:19<01:15, 4385.85it/s]\u001b[A\n",
      " 20%|█▉        | 82355/414113 [00:19<01:15, 4400.47it/s]\u001b[A\n",
      " 20%|█▉        | 82796/414113 [00:19<01:15, 4399.06it/s]\u001b[A\n",
      " 20%|██        | 83238/414113 [00:19<01:15, 4405.03it/s]\u001b[A\n",
      " 20%|██        | 83679/414113 [00:19<01:15, 4403.50it/s]\u001b[A\n",
      " 20%|██        | 84120/414113 [00:19<01:14, 4402.57it/s]\u001b[A\n",
      " 20%|██        | 84561/414113 [00:20<01:16, 4324.39it/s]\u001b[A\n",
      " 21%|██        | 84994/414113 [00:20<01:16, 4308.39it/s]\u001b[A\n",
      " 21%|██        | 85438/414113 [00:20<01:15, 4344.42it/s]\u001b[A\n",
      " 21%|██        | 85882/414113 [00:20<01:15, 4372.38it/s]\u001b[A\n",
      " 21%|██        | 86320/414113 [00:20<01:15, 4337.73it/s]\u001b[A\n",
      " 21%|██        | 86761/414113 [00:20<01:15, 4357.23it/s]\u001b[A\n",
      " 21%|██        | 87197/414113 [00:20<01:15, 4310.34it/s]\u001b[A\n",
      " 21%|██        | 87637/414113 [00:20<01:15, 4336.59it/s]\u001b[A\n",
      " 21%|██▏       | 88077/414113 [00:20<01:14, 4354.04it/s]\u001b[A\n",
      " 21%|██▏       | 88529/414113 [00:20<01:13, 4399.95it/s]\u001b[A\n",
      " 21%|██▏       | 88970/414113 [00:21<01:14, 4380.58it/s]\u001b[A\n",
      " 22%|██▏       | 89428/414113 [00:21<01:13, 4437.90it/s]\u001b[A\n",
      " 22%|██▏       | 89890/414113 [00:21<01:12, 4488.33it/s]\u001b[A\n",
      " 22%|██▏       | 90340/414113 [00:21<01:12, 4475.56it/s]\u001b[A\n",
      " 22%|██▏       | 90788/414113 [00:21<01:12, 4444.67it/s]\u001b[A\n",
      " 22%|██▏       | 91233/414113 [00:21<01:12, 4430.82it/s]\u001b[A\n",
      " 22%|██▏       | 91684/414113 [00:21<01:12, 4452.95it/s]\u001b[A\n",
      " 22%|██▏       | 92130/414113 [00:21<01:12, 4440.30it/s]\u001b[A\n",
      " 22%|██▏       | 92575/414113 [00:21<01:12, 4429.45it/s]\u001b[A\n",
      " 22%|██▏       | 93027/414113 [00:21<01:12, 4453.64it/s]\u001b[A\n",
      " 23%|██▎       | 93482/414113 [00:22<01:11, 4481.38it/s]\u001b[A\n",
      " 23%|██▎       | 93931/414113 [00:22<01:12, 4428.27it/s]\u001b[A\n",
      " 23%|██▎       | 94375/414113 [00:22<01:12, 4423.86it/s]\u001b[A\n",
      " 23%|██▎       | 94819/414113 [00:22<01:12, 4426.10it/s]\u001b[A\n",
      " 23%|██▎       | 95265/414113 [00:22<01:11, 4435.31it/s]\u001b[A\n",
      " 23%|██▎       | 95710/414113 [00:22<01:11, 4438.78it/s]\u001b[A\n",
      " 23%|██▎       | 96154/414113 [00:22<01:11, 4427.51it/s]\u001b[A\n",
      " 23%|██▎       | 96610/414113 [00:22<01:11, 4466.20it/s]\u001b[A\n",
      " 23%|██▎       | 97057/414113 [00:22<01:11, 4430.18it/s]\u001b[A\n",
      " 24%|██▎       | 97503/414113 [00:22<01:11, 4438.84it/s]\u001b[A\n",
      " 24%|██▎       | 97955/414113 [00:23<01:10, 4461.63it/s]\u001b[A\n",
      " 24%|██▍       | 98405/414113 [00:23<01:10, 4472.97it/s]\u001b[A\n",
      " 24%|██▍       | 98857/414113 [00:23<01:10, 4485.31it/s]\u001b[A\n",
      " 24%|██▍       | 99306/414113 [00:23<01:10, 4485.05it/s]\u001b[A\n",
      " 24%|██▍       | 99767/414113 [00:23<01:09, 4520.93it/s]\u001b[A\n",
      " 24%|██▍       | 100220/414113 [00:23<01:11, 4377.65it/s]\u001b[A\n",
      " 24%|██▍       | 100659/414113 [00:23<01:12, 4344.23it/s]\u001b[A\n",
      " 24%|██▍       | 101095/414113 [00:23<01:12, 4298.88it/s]\u001b[A\n",
      " 25%|██▍       | 101526/414113 [00:23<01:13, 4260.30it/s]\u001b[A\n",
      " 25%|██▍       | 101953/414113 [00:24<02:10, 2398.48it/s]\u001b[A\n",
      " 25%|██▍       | 102404/414113 [00:24<01:51, 2790.12it/s]\u001b[A\n",
      " 25%|██▍       | 102860/414113 [00:24<01:38, 3156.53it/s]\u001b[A\n",
      " 25%|██▍       | 103303/414113 [00:24<01:30, 3453.26it/s]\u001b[A\n",
      " 25%|██▌       | 103746/414113 [00:24<01:23, 3696.91it/s]\u001b[A\n",
      " 25%|██▌       | 104186/414113 [00:24<01:19, 3882.00it/s]\u001b[A\n",
      " 25%|██▌       | 104612/414113 [00:24<01:17, 3978.74it/s]\u001b[A\n",
      " 25%|██▌       | 105037/414113 [00:24<01:16, 4055.77it/s]\u001b[A\n",
      " 25%|██▌       | 105467/414113 [00:25<01:14, 4125.20it/s]\u001b[A\n",
      " 26%|██▌       | 105899/414113 [00:25<01:13, 4179.28it/s]\u001b[A\n",
      " 26%|██▌       | 106327/414113 [00:25<01:13, 4196.60it/s]\u001b[A\n",
      " 26%|██▌       | 106770/414113 [00:25<01:12, 4263.67it/s]\u001b[A\n",
      " 26%|██▌       | 107209/414113 [00:25<01:11, 4298.65it/s]\u001b[A\n",
      " 26%|██▌       | 107643/414113 [00:25<01:11, 4293.86it/s]\u001b[A\n",
      " 26%|██▌       | 108076/414113 [00:25<01:11, 4303.80it/s]\u001b[A\n",
      " 26%|██▌       | 108509/414113 [00:25<01:10, 4305.23it/s]\u001b[A\n",
      " 26%|██▋       | 108941/414113 [00:25<01:11, 4294.91it/s]\u001b[A\n",
      " 26%|██▋       | 109372/414113 [00:25<01:11, 4274.19it/s]\u001b[A\n",
      " 27%|██▋       | 109821/414113 [00:26<01:10, 4334.22it/s]\u001b[A\n",
      " 27%|██▋       | 110262/414113 [00:26<01:09, 4356.62it/s]\u001b[A\n",
      " 27%|██▋       | 110715/414113 [00:26<01:08, 4406.97it/s]\u001b[A\n",
      " 27%|██▋       | 111167/414113 [00:26<01:08, 4438.16it/s]\u001b[A\n",
      " 27%|██▋       | 111612/414113 [00:26<01:09, 4373.57it/s]\u001b[A\n",
      " 27%|██▋       | 112063/414113 [00:26<01:08, 4411.14it/s]\u001b[A\n",
      " 27%|██▋       | 112505/414113 [00:26<01:08, 4388.82it/s]\u001b[A\n",
      " 27%|██▋       | 112951/414113 [00:26<01:08, 4409.02it/s]\u001b[A\n",
      " 27%|██▋       | 113407/414113 [00:26<01:07, 4452.69it/s]\u001b[A\n",
      " 27%|██▋       | 113861/414113 [00:26<01:07, 4473.56it/s]\u001b[A\n",
      " 28%|██▊       | 114310/414113 [00:27<01:06, 4478.41it/s]\u001b[A\n",
      " 28%|██▊       | 114762/414113 [00:27<01:06, 4489.08it/s]\u001b[A\n",
      " 28%|██▊       | 115224/414113 [00:27<01:06, 4525.37it/s]\u001b[A\n",
      " 28%|██▊       | 115677/414113 [00:27<01:06, 4520.73it/s]\u001b[A\n",
      " 28%|██▊       | 116138/414113 [00:27<01:05, 4543.98it/s]\u001b[A\n",
      " 28%|██▊       | 116593/414113 [00:27<01:05, 4513.46it/s]\u001b[A\n",
      " 28%|██▊       | 117045/414113 [00:27<01:06, 4448.52it/s]\u001b[A\n",
      " 28%|██▊       | 117494/414113 [00:27<01:06, 4459.75it/s]\u001b[A\n",
      " 28%|██▊       | 117951/414113 [00:27<01:05, 4492.14it/s]\u001b[A\n",
      " 29%|██▊       | 118401/414113 [00:27<01:07, 4413.19it/s]\u001b[A\n",
      " 29%|██▊       | 118846/414113 [00:28<01:06, 4422.20it/s]\u001b[A\n",
      " 29%|██▉       | 119321/414113 [00:28<01:05, 4513.45it/s]\u001b[A\n",
      " 29%|██▉       | 119774/414113 [00:28<01:05, 4471.56it/s]\u001b[A\n",
      " 29%|██▉       | 120227/414113 [00:28<01:05, 4487.40it/s]\u001b[A\n",
      " 29%|██▉       | 120677/414113 [00:28<01:05, 4479.58it/s]\u001b[A\n",
      " 29%|██▉       | 121137/414113 [00:28<01:04, 4513.81it/s]\u001b[A\n",
      " 29%|██▉       | 121597/414113 [00:28<01:04, 4538.57it/s]\u001b[A\n",
      " 29%|██▉       | 122052/414113 [00:28<01:04, 4493.76it/s]\u001b[A\n",
      " 30%|██▉       | 122502/414113 [00:28<01:05, 4455.26it/s]\u001b[A\n",
      " 30%|██▉       | 122948/414113 [00:28<01:06, 4345.97it/s]\u001b[A\n",
      " 30%|██▉       | 123392/414113 [00:29<01:06, 4372.85it/s]\u001b[A\n",
      " 30%|██▉       | 123841/414113 [00:29<01:05, 4405.79it/s]\u001b[A\n",
      " 30%|███       | 124291/414113 [00:29<01:05, 4431.24it/s]\u001b[A\n",
      " 30%|███       | 124736/414113 [00:29<01:05, 4434.34it/s]\u001b[A\n",
      " 30%|███       | 125188/414113 [00:29<01:04, 4457.57it/s]\u001b[A\n",
      " 30%|███       | 125634/414113 [00:29<01:05, 4436.53it/s]\u001b[A\n",
      " 30%|███       | 126078/414113 [00:29<01:05, 4408.47it/s]\u001b[A\n",
      " 31%|███       | 126520/414113 [00:29<01:05, 4387.71it/s]\u001b[A\n",
      " 31%|███       | 126959/414113 [00:29<01:05, 4385.78it/s]\u001b[A\n",
      " 31%|███       | 127398/414113 [00:30<01:05, 4377.11it/s]\u001b[A\n",
      " 31%|███       | 127836/414113 [00:30<01:05, 4338.20it/s]\u001b[A\n",
      " 31%|███       | 128278/414113 [00:30<01:05, 4361.95it/s]\u001b[A\n",
      " 31%|███       | 128715/414113 [00:30<01:05, 4333.48it/s]\u001b[A\n",
      " 31%|███       | 129156/414113 [00:30<01:05, 4355.36it/s]\u001b[A\n",
      " 31%|███▏      | 129604/414113 [00:30<01:04, 4391.50it/s]\u001b[A\n",
      " 31%|███▏      | 130047/414113 [00:30<01:04, 4402.68it/s]\u001b[A\n",
      " 32%|███▏      | 130497/414113 [00:30<01:04, 4429.66it/s]\u001b[A\n",
      " 32%|███▏      | 130941/414113 [00:30<01:04, 4407.08it/s]\u001b[A\n",
      " 32%|███▏      | 131386/414113 [00:30<01:04, 4417.53it/s]\u001b[A\n",
      " 32%|███▏      | 131828/414113 [00:31<01:04, 4388.12it/s]\u001b[A\n",
      " 32%|███▏      | 132267/414113 [00:31<01:05, 4329.48it/s]\u001b[A\n",
      " 32%|███▏      | 132724/414113 [00:31<01:03, 4398.42it/s]\u001b[A\n",
      " 32%|███▏      | 133166/414113 [00:31<01:03, 4404.52it/s]\u001b[A\n",
      " 32%|███▏      | 133607/414113 [00:31<01:03, 4394.62it/s]\u001b[A\n",
      " 32%|███▏      | 134047/414113 [00:31<01:03, 4384.74it/s]\u001b[A\n",
      " 32%|███▏      | 134486/414113 [00:31<01:04, 4358.99it/s]\u001b[A\n",
      " 33%|███▎      | 134923/414113 [00:31<01:04, 4330.76it/s]\u001b[A\n",
      " 33%|███▎      | 135357/414113 [00:31<01:05, 4287.88it/s]\u001b[A\n",
      " 33%|███▎      | 135796/414113 [00:31<01:04, 4318.00it/s]\u001b[A\n",
      " 33%|███▎      | 136228/414113 [00:32<01:04, 4301.33it/s]\u001b[A\n",
      " 33%|███▎      | 136665/414113 [00:32<01:04, 4318.01it/s]\u001b[A\n",
      " 33%|███▎      | 137097/414113 [00:32<01:04, 4303.31it/s]\u001b[A\n",
      " 33%|███▎      | 137528/414113 [00:32<01:04, 4292.70it/s]\u001b[A\n",
      " 33%|███▎      | 137958/414113 [00:32<01:04, 4282.51it/s]\u001b[A\n",
      " 33%|███▎      | 138393/414113 [00:32<01:04, 4300.92it/s]\u001b[A\n",
      " 34%|███▎      | 138824/414113 [00:32<01:04, 4251.72it/s]\u001b[A\n",
      " 34%|███▎      | 139250/414113 [00:32<01:04, 4250.20it/s]\u001b[A\n",
      " 34%|███▎      | 139676/414113 [00:32<01:07, 4092.28it/s]\u001b[A\n",
      " 34%|███▍      | 140087/414113 [00:32<01:07, 4059.39it/s]\u001b[A\n",
      " 34%|███▍      | 140519/414113 [00:33<01:06, 4133.82it/s]\u001b[A\n",
      " 34%|███▍      | 140956/414113 [00:33<01:05, 4199.92it/s]\u001b[A\n",
      " 34%|███▍      | 141392/414113 [00:33<01:04, 4244.63it/s]\u001b[A\n",
      " 34%|███▍      | 141821/414113 [00:33<01:03, 4257.57it/s]\u001b[A\n",
      " 34%|███▍      | 142248/414113 [00:33<01:03, 4249.39it/s]\u001b[A\n",
      " 34%|███▍      | 142688/414113 [00:33<01:03, 4292.04it/s]\u001b[A\n",
      " 35%|███▍      | 143118/414113 [00:33<01:06, 4097.69it/s]\u001b[A\n",
      " 35%|███▍      | 143543/414113 [00:33<01:05, 4141.96it/s]\u001b[A\n",
      " 35%|███▍      | 143967/414113 [00:33<01:04, 4170.02it/s]\u001b[A\n",
      " 35%|███▍      | 144409/414113 [00:33<01:03, 4241.83it/s]\u001b[A\n",
      " 35%|███▍      | 144848/414113 [00:34<01:02, 4282.23it/s]\u001b[A\n",
      " 35%|███▌      | 145285/414113 [00:34<01:02, 4305.81it/s]\u001b[A\n",
      " 35%|███▌      | 145742/414113 [00:34<01:01, 4380.94it/s]\u001b[A\n",
      " 35%|███▌      | 146185/414113 [00:34<01:00, 4393.44it/s]\u001b[A\n",
      " 35%|███▌      | 146625/414113 [00:34<01:00, 4388.08it/s]\u001b[A\n",
      " 36%|███▌      | 147066/414113 [00:34<01:00, 4394.03it/s]\u001b[A\n",
      " 36%|███▌      | 147506/414113 [00:34<01:00, 4380.26it/s]\u001b[A\n",
      " 36%|███▌      | 147945/414113 [00:34<01:01, 4344.32it/s]\u001b[A\n",
      " 36%|███▌      | 148380/414113 [00:34<01:01, 4305.82it/s]\u001b[A\n",
      " 36%|███▌      | 148811/414113 [00:34<01:01, 4302.29it/s]\u001b[A\n",
      " 36%|███▌      | 149249/414113 [00:35<01:01, 4324.99it/s]\u001b[A\n",
      " 36%|███▌      | 149700/414113 [00:35<01:00, 4375.83it/s]\u001b[A\n",
      " 36%|███▋      | 150138/414113 [00:35<01:00, 4353.84it/s]\u001b[A\n",
      " 36%|███▋      | 150576/414113 [00:35<01:00, 4360.16it/s]\u001b[A\n",
      " 36%|███▋      | 151013/414113 [00:35<01:00, 4336.51it/s]\u001b[A\n",
      " 37%|███▋      | 151447/414113 [00:35<01:00, 4322.81it/s]\u001b[A\n",
      " 37%|███▋      | 151880/414113 [00:35<01:00, 4313.95it/s]\u001b[A\n",
      " 37%|███▋      | 152312/414113 [00:35<01:01, 4283.29it/s]\u001b[A\n",
      " 37%|███▋      | 152757/414113 [00:35<01:00, 4330.50it/s]\u001b[A\n",
      " 37%|███▋      | 153191/414113 [00:35<01:00, 4319.01it/s]\u001b[A\n",
      " 37%|███▋      | 153630/414113 [00:36<01:00, 4340.04it/s]\u001b[A\n",
      " 37%|███▋      | 154084/414113 [00:36<00:59, 4397.33it/s]\u001b[A\n",
      " 37%|███▋      | 154525/414113 [00:36<00:59, 4393.78it/s]\u001b[A\n",
      " 37%|███▋      | 154965/414113 [00:36<00:59, 4384.57it/s]\u001b[A\n",
      " 38%|███▊      | 155404/414113 [00:36<00:59, 4366.35it/s]\u001b[A\n",
      " 38%|███▊      | 155841/414113 [00:36<00:59, 4363.53it/s]\u001b[A\n",
      " 38%|███▊      | 156278/414113 [00:36<00:59, 4356.25it/s]\u001b[A\n",
      " 38%|███▊      | 156744/414113 [00:36<00:57, 4440.33it/s]\u001b[A\n",
      " 38%|███▊      | 157200/414113 [00:36<00:57, 4473.78it/s]\u001b[A\n",
      " 38%|███▊      | 157648/414113 [00:36<00:57, 4461.47it/s]\u001b[A\n",
      " 38%|███▊      | 158095/414113 [00:37<00:58, 4398.62it/s]\u001b[A\n",
      " 38%|███▊      | 158536/414113 [00:37<00:58, 4339.65it/s]\u001b[A\n",
      " 38%|███▊      | 158971/414113 [00:37<00:59, 4314.20it/s]\u001b[A\n",
      " 38%|███▊      | 159403/414113 [00:37<00:59, 4300.48it/s]\u001b[A\n",
      " 39%|███▊      | 159843/414113 [00:37<00:58, 4328.89it/s]\u001b[A\n",
      " 39%|███▊      | 160277/414113 [00:37<00:59, 4269.77it/s]\u001b[A\n",
      " 39%|███▉      | 160705/414113 [00:37<01:00, 4169.09it/s]\u001b[A\n",
      " 39%|███▉      | 161136/414113 [00:37<01:00, 4208.87it/s]\u001b[A\n",
      " 39%|███▉      | 161568/414113 [00:37<00:59, 4239.66it/s]\u001b[A\n",
      " 39%|███▉      | 161998/414113 [00:38<00:59, 4256.73it/s]\u001b[A\n",
      " 39%|███▉      | 162459/414113 [00:38<00:57, 4356.82it/s]\u001b[A\n",
      " 39%|███▉      | 162904/414113 [00:38<00:57, 4381.12it/s]\u001b[A\n",
      " 39%|███▉      | 163368/414113 [00:38<00:56, 4454.00it/s]\u001b[A\n",
      " 40%|███▉      | 163815/414113 [00:38<00:56, 4432.63it/s]\u001b[A\n",
      " 40%|███▉      | 164266/414113 [00:38<00:56, 4452.76it/s]\u001b[A\n",
      " 40%|███▉      | 164712/414113 [00:38<00:56, 4423.69it/s]\u001b[A\n",
      " 40%|███▉      | 165155/414113 [00:38<00:57, 4364.07it/s]\u001b[A\n",
      " 40%|███▉      | 165592/414113 [00:38<00:57, 4295.83it/s]\u001b[A\n",
      " 40%|████      | 166023/414113 [00:38<00:58, 4271.39it/s]\u001b[A\n",
      " 40%|████      | 166451/414113 [00:39<00:58, 4237.40it/s]\u001b[A\n",
      " 40%|████      | 166876/414113 [00:39<00:58, 4239.39it/s]\u001b[A\n",
      " 40%|████      | 167309/414113 [00:39<00:57, 4263.91it/s]\u001b[A\n",
      " 41%|████      | 167737/414113 [00:39<00:57, 4267.51it/s]\u001b[A\n",
      " 41%|████      | 168181/414113 [00:39<00:56, 4316.32it/s]\u001b[A\n",
      " 41%|████      | 168613/414113 [00:39<00:56, 4312.94it/s]\u001b[A\n",
      " 41%|████      | 169045/414113 [00:39<00:56, 4305.67it/s]\u001b[A\n",
      " 41%|████      | 169480/414113 [00:39<00:56, 4317.44it/s]\u001b[A\n",
      " 41%|████      | 169912/414113 [00:39<00:57, 4236.48it/s]\u001b[A\n",
      " 41%|████      | 170348/414113 [00:39<00:57, 4271.95it/s]\u001b[A\n",
      " 41%|████      | 170780/414113 [00:40<00:56, 4284.12it/s]\u001b[A\n",
      " 41%|████▏     | 171209/414113 [00:40<00:56, 4266.84it/s]\u001b[A\n",
      " 41%|████▏     | 171644/414113 [00:40<00:56, 4290.94it/s]\u001b[A\n",
      " 42%|████▏     | 172076/414113 [00:40<00:56, 4298.23it/s]\u001b[A\n",
      " 42%|████▏     | 172506/414113 [00:40<00:56, 4252.81it/s]\u001b[A\n",
      " 42%|████▏     | 172932/414113 [00:40<00:56, 4245.23it/s]\u001b[A\n",
      " 42%|████▏     | 173357/414113 [00:40<00:56, 4228.97it/s]\u001b[A\n",
      " 42%|████▏     | 173787/414113 [00:40<00:56, 4249.06it/s]\u001b[A\n",
      " 42%|████▏     | 174213/414113 [00:40<00:56, 4230.97it/s]\u001b[A\n",
      " 42%|████▏     | 174637/414113 [00:40<00:56, 4225.98it/s]\u001b[A\n",
      " 42%|████▏     | 175060/414113 [00:41<00:56, 4211.29it/s]\u001b[A\n",
      " 42%|████▏     | 175482/414113 [00:41<00:57, 4148.52it/s]\u001b[A\n",
      " 42%|████▏     | 175923/414113 [00:41<00:56, 4221.40it/s]\u001b[A\n",
      " 43%|████▎     | 176356/414113 [00:41<00:55, 4253.10it/s]\u001b[A\n",
      " 43%|████▎     | 176786/414113 [00:41<00:55, 4264.77it/s]\u001b[A\n",
      " 43%|████▎     | 177213/414113 [00:41<00:55, 4251.85it/s]\u001b[A\n",
      " 43%|████▎     | 177639/414113 [00:41<00:55, 4248.04it/s]\u001b[A\n",
      " 43%|████▎     | 178064/414113 [00:41<00:55, 4239.39it/s]\u001b[A\n",
      " 43%|████▎     | 178489/414113 [00:41<00:55, 4222.89it/s]\u001b[A\n",
      " 43%|████▎     | 178927/414113 [00:41<00:55, 4268.23it/s]\u001b[A\n",
      " 43%|████▎     | 179362/414113 [00:42<00:54, 4291.41it/s]\u001b[A\n",
      " 43%|████▎     | 179792/414113 [00:42<00:54, 4292.80it/s]\u001b[A\n",
      " 44%|████▎     | 180224/414113 [00:42<00:54, 4299.56it/s]\u001b[A\n",
      " 44%|████▎     | 180655/414113 [00:42<00:54, 4262.44it/s]\u001b[A\n",
      " 44%|████▎     | 181082/414113 [00:42<00:54, 4250.43it/s]\u001b[A\n",
      " 44%|████▍     | 181526/414113 [00:42<00:54, 4305.01it/s]\u001b[A\n",
      " 44%|████▍     | 181957/414113 [00:42<00:54, 4298.64it/s]\u001b[A\n",
      " 44%|████▍     | 182388/414113 [00:42<00:53, 4297.95it/s]\u001b[A\n",
      " 44%|████▍     | 182818/414113 [00:42<00:53, 4291.42it/s]\u001b[A\n",
      " 44%|████▍     | 183249/414113 [00:42<00:53, 4294.76it/s]\u001b[A\n",
      " 44%|████▍     | 183679/414113 [00:43<00:53, 4276.61it/s]\u001b[A\n",
      " 44%|████▍     | 184107/414113 [00:43<00:54, 4249.03it/s]\u001b[A\n",
      " 45%|████▍     | 184532/414113 [00:43<00:54, 4235.15it/s]\u001b[A\n",
      " 45%|████▍     | 184957/414113 [00:43<00:54, 4236.17it/s]\u001b[A\n",
      " 45%|████▍     | 185393/414113 [00:43<00:53, 4270.73it/s]\u001b[A\n",
      " 45%|████▍     | 185821/414113 [00:43<00:53, 4232.48it/s]\u001b[A\n",
      " 45%|████▍     | 186256/414113 [00:43<00:53, 4266.65it/s]\u001b[A\n",
      " 45%|████▌     | 186683/414113 [00:43<00:53, 4248.57it/s]\u001b[A\n",
      " 45%|████▌     | 187115/414113 [00:43<00:53, 4268.96it/s]\u001b[A\n",
      " 45%|████▌     | 187549/414113 [00:43<00:52, 4288.01it/s]\u001b[A\n",
      " 45%|████▌     | 187978/414113 [00:44<00:52, 4277.83it/s]\u001b[A\n",
      " 45%|████▌     | 188406/414113 [00:44<00:53, 4258.24it/s]\u001b[A\n",
      " 46%|████▌     | 188832/414113 [00:44<00:52, 4256.02it/s]\u001b[A\n",
      " 46%|████▌     | 189265/414113 [00:44<00:52, 4275.05it/s]\u001b[A\n",
      " 46%|████▌     | 189694/414113 [00:44<00:52, 4277.48it/s]\u001b[A\n",
      " 46%|████▌     | 190122/414113 [00:44<00:52, 4257.24it/s]\u001b[A\n",
      " 46%|████▌     | 190557/414113 [00:44<00:52, 4283.80it/s]\u001b[A\n",
      " 46%|████▌     | 190986/414113 [00:44<00:52, 4258.91it/s]\u001b[A\n",
      " 46%|████▌     | 191428/414113 [00:44<00:51, 4305.30it/s]\u001b[A\n",
      " 46%|████▋     | 191859/414113 [00:44<00:51, 4300.36it/s]\u001b[A\n",
      " 46%|████▋     | 192298/414113 [00:45<00:51, 4325.28it/s]\u001b[A\n",
      " 47%|████▋     | 192731/414113 [00:45<00:51, 4291.79it/s]\u001b[A\n",
      " 47%|████▋     | 193164/414113 [00:45<00:51, 4301.35it/s]\u001b[A\n",
      " 47%|████▋     | 193597/414113 [00:45<00:51, 4307.11it/s]\u001b[A\n",
      " 47%|████▋     | 194037/414113 [00:45<00:50, 4331.90it/s]\u001b[A\n",
      " 47%|████▋     | 194471/414113 [00:45<00:50, 4327.63it/s]\u001b[A\n",
      " 47%|████▋     | 194904/414113 [00:45<00:50, 4311.40it/s]\u001b[A\n",
      " 47%|████▋     | 195343/414113 [00:45<00:50, 4333.73it/s]\u001b[A\n",
      " 47%|████▋     | 195779/414113 [00:45<00:50, 4341.00it/s]\u001b[A\n",
      " 47%|████▋     | 196214/414113 [00:46<00:50, 4340.61it/s]\u001b[A\n",
      " 47%|████▋     | 196649/414113 [00:46<00:50, 4311.57it/s]\u001b[A\n",
      " 48%|████▊     | 197087/414113 [00:46<00:50, 4331.20it/s]\u001b[A\n",
      " 48%|████▊     | 197525/414113 [00:46<00:49, 4343.03it/s]\u001b[A\n",
      " 48%|████▊     | 197968/414113 [00:46<00:49, 4368.45it/s]\u001b[A\n",
      " 48%|████▊     | 198406/414113 [00:46<00:49, 4370.98it/s]\u001b[A\n",
      " 48%|████▊     | 198847/414113 [00:46<00:49, 4382.60it/s]\u001b[A\n",
      " 48%|████▊     | 199292/414113 [00:46<00:48, 4399.24it/s]\u001b[A\n",
      " 48%|████▊     | 199732/414113 [00:46<00:48, 4385.81it/s]\u001b[A\n",
      " 48%|████▊     | 200171/414113 [00:46<00:49, 4361.30it/s]\u001b[A\n",
      " 48%|████▊     | 200608/414113 [00:47<00:49, 4341.49it/s]\u001b[A\n",
      " 49%|████▊     | 201048/414113 [00:47<00:48, 4357.92it/s]\u001b[A\n",
      " 49%|████▊     | 201497/414113 [00:47<00:48, 4394.40it/s]\u001b[A\n",
      " 49%|████▉     | 201937/414113 [00:47<00:48, 4347.13it/s]\u001b[A\n",
      " 49%|████▉     | 202373/414113 [00:47<00:48, 4349.43it/s]\u001b[A\n",
      " 49%|████▉     | 202809/414113 [00:47<00:48, 4351.58it/s]\u001b[A\n",
      " 49%|████▉     | 203261/414113 [00:47<00:47, 4398.13it/s]\u001b[A\n",
      " 49%|████▉     | 203701/414113 [00:47<00:47, 4385.98it/s]\u001b[A\n",
      " 49%|████▉     | 204144/414113 [00:47<00:47, 4397.01it/s]\u001b[A\n",
      " 49%|████▉     | 204584/414113 [00:47<00:47, 4387.72it/s]\u001b[A\n",
      " 50%|████▉     | 205023/414113 [00:48<00:47, 4369.00it/s]\u001b[A\n",
      " 50%|████▉     | 205460/414113 [00:48<00:47, 4359.77it/s]\u001b[A\n",
      " 50%|████▉     | 205897/414113 [00:48<00:48, 4264.96it/s]\u001b[A\n",
      " 50%|████▉     | 206331/414113 [00:48<00:48, 4286.50it/s]\u001b[A\n",
      " 50%|████▉     | 206761/414113 [00:48<00:48, 4281.44it/s]\u001b[A\n",
      " 50%|█████     | 207196/414113 [00:48<00:48, 4299.41it/s]\u001b[A\n",
      " 50%|█████     | 207632/414113 [00:48<00:47, 4315.49it/s]\u001b[A\n",
      " 50%|█████     | 208068/414113 [00:48<00:47, 4328.03it/s]\u001b[A\n",
      " 50%|█████     | 208501/414113 [00:48<00:47, 4301.12it/s]\u001b[A\n",
      " 50%|█████     | 208944/414113 [00:48<00:47, 4336.96it/s]\u001b[A\n",
      " 51%|█████     | 209378/414113 [00:49<00:47, 4325.04it/s]\u001b[A\n",
      " 51%|█████     | 209819/414113 [00:49<00:46, 4350.11it/s]\u001b[A\n",
      " 51%|█████     | 210260/414113 [00:49<00:46, 4364.64it/s]\u001b[A\n",
      " 51%|█████     | 210706/414113 [00:49<00:46, 4391.26it/s]\u001b[A\n",
      " 51%|█████     | 211163/414113 [00:49<00:45, 4442.71it/s]\u001b[A\n",
      " 51%|█████     | 211625/414113 [00:49<00:45, 4494.41it/s]\u001b[A\n",
      " 51%|█████     | 212075/414113 [00:49<00:45, 4444.46it/s]\u001b[A\n",
      " 51%|█████▏    | 212524/414113 [00:49<00:45, 4457.02it/s]\u001b[A\n",
      " 51%|█████▏    | 212989/414113 [00:49<00:44, 4512.71it/s]\u001b[A\n",
      " 52%|█████▏    | 213441/414113 [00:49<00:44, 4478.47it/s]\u001b[A\n",
      " 52%|█████▏    | 213890/414113 [00:50<00:44, 4459.86it/s]\u001b[A\n",
      " 52%|█████▏    | 214342/414113 [00:50<00:44, 4477.08it/s]\u001b[A\n",
      " 52%|█████▏    | 214805/414113 [00:50<00:44, 4520.44it/s]\u001b[A\n",
      " 52%|█████▏    | 215258/414113 [00:50<00:44, 4509.49it/s]\u001b[A\n",
      " 52%|█████▏    | 215710/414113 [00:50<00:44, 4499.09it/s]\u001b[A\n",
      " 52%|█████▏    | 216173/414113 [00:50<00:43, 4534.94it/s]\u001b[A\n",
      " 52%|█████▏    | 216627/414113 [00:50<00:44, 4482.72it/s]\u001b[A\n",
      " 52%|█████▏    | 217076/414113 [00:50<00:44, 4470.17it/s]\u001b[A\n",
      " 53%|█████▎    | 217524/414113 [00:50<00:44, 4428.48it/s]\u001b[A\n",
      " 53%|█████▎    | 217968/414113 [00:50<00:44, 4429.72it/s]\u001b[A\n",
      " 53%|█████▎    | 218412/414113 [00:51<00:45, 4321.79it/s]\u001b[A\n",
      " 53%|█████▎    | 218846/414113 [00:51<00:45, 4326.10it/s]\u001b[A\n",
      " 53%|█████▎    | 219323/414113 [00:51<00:43, 4449.92it/s]\u001b[A\n",
      " 53%|█████▎    | 219770/414113 [00:51<00:44, 4398.75it/s]\u001b[A\n",
      " 53%|█████▎    | 220211/414113 [00:51<00:44, 4390.20it/s]\u001b[A\n",
      " 53%|█████▎    | 220653/414113 [00:51<00:43, 4397.73it/s]\u001b[A\n",
      " 53%|█████▎    | 221094/414113 [00:51<00:44, 4364.25it/s]\u001b[A\n",
      " 53%|█████▎    | 221531/414113 [00:51<00:44, 4326.97it/s]\u001b[A\n",
      " 54%|█████▎    | 221981/414113 [00:51<00:43, 4376.07it/s]\u001b[A\n",
      " 54%|█████▎    | 222430/414113 [00:51<00:43, 4409.52it/s]\u001b[A\n",
      " 54%|█████▍    | 222877/414113 [00:52<00:43, 4424.84it/s]\u001b[A\n",
      " 54%|█████▍    | 223330/414113 [00:52<00:42, 4454.05it/s]\u001b[A\n",
      " 54%|█████▍    | 223798/414113 [00:52<00:42, 4518.86it/s]\u001b[A\n",
      " 54%|█████▍    | 224256/414113 [00:52<00:41, 4534.68it/s]\u001b[A\n",
      " 54%|█████▍    | 224720/414113 [00:52<00:41, 4563.51it/s]\u001b[A\n",
      " 54%|█████▍    | 225177/414113 [00:52<00:41, 4530.02it/s]\u001b[A\n",
      " 54%|█████▍    | 225631/414113 [00:52<00:42, 4481.58it/s]\u001b[A\n",
      " 55%|█████▍    | 226080/414113 [00:52<00:42, 4419.05it/s]\u001b[A\n",
      " 55%|█████▍    | 226525/414113 [00:52<00:42, 4427.47it/s]\u001b[A\n",
      " 55%|█████▍    | 226981/414113 [00:52<00:41, 4465.49it/s]\u001b[A\n",
      " 55%|█████▍    | 227428/414113 [00:53<01:18, 2367.41it/s]\u001b[A\n",
      " 55%|█████▌    | 227922/414113 [00:53<01:06, 2804.99it/s]\u001b[A\n",
      " 55%|█████▌    | 228328/414113 [00:53<01:00, 3091.52it/s]\u001b[A\n",
      " 55%|█████▌    | 228769/414113 [00:53<00:54, 3396.11it/s]\u001b[A\n",
      " 55%|█████▌    | 229210/414113 [00:53<00:50, 3646.51it/s]\u001b[A\n",
      " 55%|█████▌    | 229643/414113 [00:53<00:48, 3825.70it/s]\u001b[A\n",
      " 56%|█████▌    | 230080/414113 [00:53<00:46, 3973.10it/s]\u001b[A\n",
      " 56%|█████▌    | 230507/414113 [00:54<00:45, 4049.27it/s]\u001b[A\n",
      " 56%|█████▌    | 230943/414113 [00:54<00:44, 4136.54it/s]\u001b[A\n",
      " 56%|█████▌    | 231380/414113 [00:54<00:43, 4202.54it/s]\u001b[A\n",
      " 56%|█████▌    | 231812/414113 [00:54<00:43, 4222.80it/s]\u001b[A\n",
      " 56%|█████▌    | 232242/414113 [00:54<00:43, 4203.35it/s]\u001b[A\n",
      " 56%|█████▌    | 232668/414113 [00:54<00:43, 4207.22it/s]\u001b[A\n",
      " 56%|█████▋    | 233093/414113 [00:54<00:42, 4213.62it/s]\u001b[A\n",
      " 56%|█████▋    | 233522/414113 [00:54<00:42, 4234.16it/s]\u001b[A\n",
      " 56%|█████▋    | 233970/414113 [00:54<00:41, 4303.00it/s]\u001b[A\n",
      " 57%|█████▋    | 234412/414113 [00:54<00:41, 4336.14it/s]\u001b[A\n",
      " 57%|█████▋    | 234853/414113 [00:55<00:41, 4354.17it/s]\u001b[A\n",
      " 57%|█████▋    | 235302/414113 [00:55<00:40, 4392.44it/s]\u001b[A\n",
      " 57%|█████▋    | 235764/414113 [00:55<00:40, 4455.18it/s]\u001b[A\n",
      " 57%|█████▋    | 236217/414113 [00:55<00:39, 4477.31it/s]\u001b[A\n",
      " 57%|█████▋    | 236678/414113 [00:55<00:39, 4516.23it/s]\u001b[A\n",
      " 57%|█████▋    | 237132/414113 [00:55<00:39, 4521.12it/s]\u001b[A\n",
      " 57%|█████▋    | 237590/414113 [00:55<00:38, 4536.71it/s]\u001b[A\n",
      " 57%|█████▋    | 238044/414113 [00:55<00:39, 4471.37it/s]\u001b[A\n",
      " 58%|█████▊    | 238492/414113 [00:55<00:40, 4381.13it/s]\u001b[A\n",
      " 58%|█████▊    | 238931/414113 [00:56<00:40, 4349.78it/s]\u001b[A\n",
      " 58%|█████▊    | 239389/414113 [00:56<00:39, 4414.40it/s]\u001b[A\n",
      " 58%|█████▊    | 239849/414113 [00:56<00:39, 4467.00it/s]\u001b[A\n",
      " 58%|█████▊    | 240315/414113 [00:56<00:38, 4521.40it/s]\u001b[A\n",
      " 58%|█████▊    | 240768/414113 [00:56<00:38, 4489.22it/s]\u001b[A\n",
      " 58%|█████▊    | 241224/414113 [00:56<00:38, 4507.95it/s]\u001b[A\n",
      " 58%|█████▊    | 241676/414113 [00:56<00:38, 4439.00it/s]\u001b[A\n",
      " 58%|█████▊    | 242121/414113 [00:56<00:39, 4380.98it/s]\u001b[A\n",
      " 59%|█████▊    | 242560/414113 [00:56<00:39, 4348.34it/s]\u001b[A\n",
      " 59%|█████▊    | 243021/414113 [00:56<00:38, 4420.73it/s]\u001b[A\n",
      " 59%|█████▉    | 243483/414113 [00:57<00:38, 4478.66it/s]\u001b[A\n",
      " 59%|█████▉    | 243932/414113 [00:57<00:38, 4455.22it/s]\u001b[A\n",
      " 59%|█████▉    | 244378/414113 [00:57<00:38, 4410.40it/s]\u001b[A\n",
      " 59%|█████▉    | 244845/414113 [00:57<00:37, 4484.21it/s]\u001b[A\n",
      " 59%|█████▉    | 245303/414113 [00:57<00:37, 4510.70it/s]\u001b[A\n",
      " 59%|█████▉    | 245760/414113 [00:57<00:37, 4526.38it/s]\u001b[A\n",
      " 59%|█████▉    | 246213/414113 [00:57<00:37, 4450.48it/s]\u001b[A\n",
      " 60%|█████▉    | 246659/414113 [00:57<00:37, 4421.79it/s]\u001b[A\n",
      " 60%|█████▉    | 247102/414113 [00:57<00:37, 4422.72it/s]\u001b[A\n",
      " 60%|█████▉    | 247548/414113 [00:57<00:37, 4433.49it/s]\u001b[A\n",
      " 60%|█████▉    | 247999/414113 [00:58<00:37, 4454.02it/s]\u001b[A\n",
      " 60%|█████▉    | 248446/414113 [00:58<00:37, 4456.65it/s]\u001b[A\n",
      " 60%|██████    | 248907/414113 [00:58<00:36, 4501.50it/s]\u001b[A\n",
      " 60%|██████    | 249375/414113 [00:58<00:36, 4551.68it/s]\u001b[A\n",
      " 60%|██████    | 249831/414113 [00:58<00:36, 4532.74it/s]\u001b[A\n",
      " 60%|██████    | 250285/414113 [00:58<00:36, 4530.77it/s]\u001b[A\n",
      " 61%|██████    | 250739/414113 [00:58<00:36, 4508.09it/s]\u001b[A\n",
      " 61%|██████    | 251190/414113 [00:58<00:36, 4453.57it/s]\u001b[A\n",
      " 61%|██████    | 251645/414113 [00:58<00:36, 4479.04it/s]\u001b[A\n",
      " 61%|██████    | 252094/414113 [00:58<00:36, 4456.66it/s]\u001b[A\n",
      " 61%|██████    | 252540/414113 [00:59<00:36, 4393.40it/s]\u001b[A\n",
      " 61%|██████    | 252980/414113 [00:59<00:36, 4368.82it/s]\u001b[A\n",
      " 61%|██████    | 253418/414113 [00:59<00:36, 4368.84it/s]\u001b[A\n",
      " 61%|██████▏   | 253860/414113 [00:59<00:36, 4381.37it/s]\u001b[A\n",
      " 61%|██████▏   | 254299/414113 [00:59<00:36, 4352.96it/s]\u001b[A\n",
      " 62%|██████▏   | 254737/414113 [00:59<00:36, 4358.61it/s]\u001b[A\n",
      " 62%|██████▏   | 255189/414113 [00:59<00:36, 4405.28it/s]\u001b[A\n",
      " 62%|██████▏   | 255630/414113 [00:59<00:36, 4336.35it/s]\u001b[A\n",
      " 62%|██████▏   | 256068/414113 [00:59<00:36, 4348.18it/s]\u001b[A\n",
      " 62%|██████▏   | 256505/414113 [00:59<00:36, 4352.81it/s]\u001b[A\n",
      " 62%|██████▏   | 256953/414113 [01:00<00:35, 4388.52it/s]\u001b[A\n",
      " 62%|██████▏   | 257403/414113 [01:00<00:35, 4419.35it/s]\u001b[A\n",
      " 62%|██████▏   | 257846/414113 [01:00<00:35, 4367.51it/s]\u001b[A\n",
      " 62%|██████▏   | 258284/414113 [01:00<00:36, 4327.20it/s]\u001b[A\n",
      " 62%|██████▏   | 258717/414113 [01:00<00:36, 4316.53it/s]\u001b[A\n",
      " 63%|██████▎   | 259149/414113 [01:00<00:36, 4290.03it/s]\u001b[A\n",
      " 63%|██████▎   | 259587/414113 [01:00<00:35, 4316.14it/s]\u001b[A\n",
      " 63%|██████▎   | 260019/414113 [01:00<00:35, 4289.62it/s]\u001b[A\n",
      " 63%|██████▎   | 260459/414113 [01:00<00:35, 4321.66it/s]\u001b[A\n",
      " 63%|██████▎   | 260906/414113 [01:00<00:35, 4364.44it/s]\u001b[A\n",
      " 63%|██████▎   | 261356/414113 [01:01<00:34, 4403.00it/s]\u001b[A\n",
      " 63%|██████▎   | 261797/414113 [01:01<00:34, 4391.20it/s]\u001b[A\n",
      " 63%|██████▎   | 262237/414113 [01:01<00:34, 4351.71it/s]\u001b[A\n",
      " 63%|██████▎   | 262673/414113 [01:01<00:34, 4335.64it/s]\u001b[A\n",
      " 64%|██████▎   | 263107/414113 [01:01<00:35, 4314.12it/s]\u001b[A\n",
      " 64%|██████▎   | 263543/414113 [01:01<00:34, 4327.59it/s]\u001b[A\n",
      " 64%|██████▎   | 263976/414113 [01:01<00:34, 4321.33it/s]\u001b[A\n",
      " 64%|██████▍   | 264409/414113 [01:01<00:35, 4223.80it/s]\u001b[A\n",
      " 64%|██████▍   | 264845/414113 [01:01<00:35, 4261.98it/s]\u001b[A\n",
      " 64%|██████▍   | 265286/414113 [01:01<00:34, 4302.89it/s]\u001b[A\n",
      " 64%|██████▍   | 265724/414113 [01:02<00:34, 4324.44it/s]\u001b[A\n",
      " 64%|██████▍   | 266157/414113 [01:02<00:34, 4277.09it/s]\u001b[A\n",
      " 64%|██████▍   | 266623/414113 [01:02<00:33, 4383.42it/s]\u001b[A\n",
      " 64%|██████▍   | 267063/414113 [01:02<00:33, 4372.09it/s]\u001b[A\n",
      " 65%|██████▍   | 267503/414113 [01:02<00:33, 4377.36it/s]\u001b[A\n",
      " 65%|██████▍   | 267943/414113 [01:02<00:33, 4383.15it/s]\u001b[A\n",
      " 65%|██████▍   | 268393/414113 [01:02<00:32, 4415.88it/s]\u001b[A\n",
      " 65%|██████▍   | 268835/414113 [01:02<00:32, 4406.96it/s]\u001b[A\n",
      " 65%|██████▌   | 269276/414113 [01:02<00:33, 4386.01it/s]\u001b[A\n",
      " 65%|██████▌   | 269718/414113 [01:02<00:32, 4395.65it/s]\u001b[A\n",
      " 65%|██████▌   | 270158/414113 [01:03<00:32, 4393.98it/s]\u001b[A\n",
      " 65%|██████▌   | 270613/414113 [01:03<00:32, 4439.09it/s]\u001b[A\n",
      " 65%|██████▌   | 271069/414113 [01:03<00:31, 4473.38it/s]\u001b[A\n",
      " 66%|██████▌   | 271517/414113 [01:03<00:32, 4450.15it/s]\u001b[A\n",
      " 66%|██████▌   | 271963/414113 [01:03<00:32, 4398.88it/s]\u001b[A\n",
      " 66%|██████▌   | 272404/414113 [01:03<00:32, 4367.89it/s]\u001b[A\n",
      " 66%|██████▌   | 272855/414113 [01:03<00:32, 4407.18it/s]\u001b[A\n",
      " 66%|██████▌   | 273309/414113 [01:03<00:31, 4444.16it/s]\u001b[A\n",
      " 66%|██████▌   | 273754/414113 [01:03<00:31, 4441.00it/s]\u001b[A\n",
      " 66%|██████▌   | 274199/414113 [01:04<00:31, 4394.08it/s]\u001b[A\n",
      " 66%|██████▋   | 274639/414113 [01:04<00:31, 4360.14it/s]\u001b[A\n",
      " 66%|██████▋   | 275076/414113 [01:04<00:32, 4312.03it/s]\u001b[A\n",
      " 67%|██████▋   | 275515/414113 [01:04<00:31, 4333.13it/s]\u001b[A\n",
      " 67%|██████▋   | 275950/414113 [01:04<00:31, 4337.96it/s]\u001b[A\n",
      " 67%|██████▋   | 276385/414113 [01:04<00:31, 4340.27it/s]\u001b[A\n",
      " 67%|██████▋   | 276820/414113 [01:04<00:31, 4322.54it/s]\u001b[A\n",
      " 67%|██████▋   | 277253/414113 [01:04<00:31, 4290.64it/s]\u001b[A\n",
      " 67%|██████▋   | 277688/414113 [01:04<00:31, 4304.47it/s]\u001b[A\n",
      " 67%|██████▋   | 278125/414113 [01:04<00:31, 4322.00it/s]\u001b[A\n",
      " 67%|██████▋   | 278565/414113 [01:05<00:31, 4343.29it/s]\u001b[A\n",
      " 67%|██████▋   | 279003/414113 [01:05<00:31, 4352.40it/s]\u001b[A\n",
      " 67%|██████▋   | 279450/414113 [01:05<00:30, 4386.27it/s]\u001b[A\n",
      " 68%|██████▊   | 279889/414113 [01:05<00:30, 4330.21it/s]\u001b[A\n",
      " 68%|██████▊   | 280323/414113 [01:05<00:31, 4310.04it/s]\u001b[A\n",
      " 68%|██████▊   | 280757/414113 [01:05<00:30, 4316.70it/s]\u001b[A\n",
      " 68%|██████▊   | 281192/414113 [01:05<00:30, 4325.62it/s]\u001b[A\n",
      " 68%|██████▊   | 281625/414113 [01:05<00:30, 4321.58it/s]\u001b[A\n",
      " 68%|██████▊   | 282058/414113 [01:05<00:30, 4297.14it/s]\u001b[A\n",
      " 68%|██████▊   | 282491/414113 [01:05<00:30, 4304.72it/s]\u001b[A\n",
      " 68%|██████▊   | 282942/414113 [01:06<00:30, 4362.65it/s]\u001b[A\n",
      " 68%|██████▊   | 283404/414113 [01:06<00:29, 4436.77it/s]\u001b[A\n",
      " 69%|██████▊   | 283862/414113 [01:06<00:29, 4478.19it/s]\u001b[A\n",
      " 69%|██████▊   | 284312/414113 [01:06<00:28, 4482.50it/s]\u001b[A\n",
      " 69%|██████▉   | 284761/414113 [01:06<00:28, 4475.29it/s]\u001b[A\n",
      " 69%|██████▉   | 285209/414113 [01:06<00:28, 4453.12it/s]\u001b[A\n",
      " 69%|██████▉   | 285655/414113 [01:06<00:29, 4421.98it/s]\u001b[A\n",
      " 69%|██████▉   | 286104/414113 [01:06<00:28, 4439.26it/s]\u001b[A\n",
      " 69%|██████▉   | 286549/414113 [01:06<00:28, 4411.62it/s]\u001b[A\n",
      " 69%|██████▉   | 286991/414113 [01:06<00:28, 4390.80it/s]\u001b[A\n",
      " 69%|██████▉   | 287436/414113 [01:07<00:28, 4405.52it/s]\u001b[A\n",
      " 70%|██████▉   | 287877/414113 [01:07<00:28, 4380.44it/s]\u001b[A\n",
      " 70%|██████▉   | 288316/414113 [01:07<00:28, 4365.98it/s]\u001b[A\n",
      " 70%|██████▉   | 288758/414113 [01:07<00:28, 4381.81it/s]\u001b[A\n",
      " 70%|██████▉   | 289199/414113 [01:07<00:28, 4390.09it/s]\u001b[A\n",
      " 70%|██████▉   | 289642/414113 [01:07<00:28, 4401.02it/s]\u001b[A\n",
      " 70%|███████   | 290106/414113 [01:07<00:27, 4469.93it/s]\u001b[A\n",
      " 70%|███████   | 290558/414113 [01:07<00:27, 4483.86it/s]\u001b[A\n",
      " 70%|███████   | 291007/414113 [01:07<00:27, 4459.30it/s]\u001b[A\n",
      " 70%|███████   | 291454/414113 [01:07<00:27, 4457.32it/s]\u001b[A\n",
      " 70%|███████   | 291908/414113 [01:08<00:27, 4479.37it/s]\u001b[A\n",
      " 71%|███████   | 292369/414113 [01:08<00:26, 4514.17it/s]\u001b[A\n",
      " 71%|███████   | 292826/414113 [01:08<00:26, 4529.69it/s]\u001b[A\n",
      " 71%|███████   | 293287/414113 [01:08<00:26, 4553.02it/s]\u001b[A\n",
      " 71%|███████   | 293743/414113 [01:08<00:27, 4319.48it/s]\u001b[A\n",
      " 71%|███████   | 294192/414113 [01:08<00:27, 4364.05it/s]\u001b[A\n",
      " 71%|███████   | 294646/414113 [01:08<00:27, 4413.85it/s]\u001b[A\n",
      " 71%|███████▏  | 295089/414113 [01:08<00:26, 4412.67it/s]\u001b[A\n",
      " 71%|███████▏  | 295532/414113 [01:08<00:26, 4403.38it/s]\u001b[A\n",
      " 71%|███████▏  | 295974/414113 [01:08<00:27, 4357.54it/s]\u001b[A\n",
      " 72%|███████▏  | 296411/414113 [01:09<00:27, 4340.25it/s]\u001b[A\n",
      " 72%|███████▏  | 296851/414113 [01:09<00:26, 4357.46it/s]\u001b[A\n",
      " 72%|███████▏  | 297288/414113 [01:09<00:26, 4354.08it/s]\u001b[A\n",
      " 72%|███████▏  | 297724/414113 [01:09<00:26, 4338.36it/s]\u001b[A\n",
      " 72%|███████▏  | 298159/414113 [01:09<00:26, 4341.62it/s]\u001b[A\n",
      " 72%|███████▏  | 298619/414113 [01:09<00:26, 4415.02it/s]\u001b[A\n",
      " 72%|███████▏  | 299063/414113 [01:09<00:26, 4419.98it/s]\u001b[A\n",
      " 72%|███████▏  | 299513/414113 [01:09<00:25, 4442.43it/s]\u001b[A\n",
      " 72%|███████▏  | 299970/414113 [01:09<00:25, 4478.13it/s]\u001b[A\n",
      " 73%|███████▎  | 300421/414113 [01:09<00:25, 4486.38it/s]\u001b[A\n",
      " 73%|███████▎  | 300870/414113 [01:10<00:25, 4460.04it/s]\u001b[A\n",
      " 73%|███████▎  | 301318/414113 [01:10<00:25, 4465.95it/s]\u001b[A\n",
      " 73%|███████▎  | 301783/414113 [01:10<00:24, 4519.17it/s]\u001b[A\n",
      " 73%|███████▎  | 302236/414113 [01:10<00:25, 4441.17it/s]\u001b[A\n",
      " 73%|███████▎  | 302681/414113 [01:10<00:25, 4358.79it/s]\u001b[A\n",
      " 73%|███████▎  | 303125/414113 [01:10<00:25, 4380.12it/s]\u001b[A\n",
      " 73%|███████▎  | 303564/414113 [01:10<00:25, 4382.87it/s]\u001b[A\n",
      " 73%|███████▎  | 304003/414113 [01:10<00:25, 4340.97it/s]\u001b[A\n",
      " 74%|███████▎  | 304438/414113 [01:10<00:25, 4336.70it/s]\u001b[A\n",
      " 74%|███████▎  | 304874/414113 [01:10<00:25, 4342.43it/s]\u001b[A\n",
      " 74%|███████▎  | 305323/414113 [01:11<00:24, 4383.18it/s]\u001b[A\n",
      " 74%|███████▍  | 305776/414113 [01:11<00:24, 4424.59it/s]\u001b[A\n",
      " 74%|███████▍  | 306238/414113 [01:11<00:24, 4479.57it/s]\u001b[A\n",
      " 74%|███████▍  | 306687/414113 [01:11<00:24, 4422.21it/s]\u001b[A\n",
      " 74%|███████▍  | 307130/414113 [01:11<00:24, 4376.82it/s]\u001b[A\n",
      " 74%|███████▍  | 307570/414113 [01:11<00:24, 4383.55it/s]\u001b[A\n",
      " 74%|███████▍  | 308009/414113 [01:11<00:24, 4381.48it/s]\u001b[A\n",
      " 74%|███████▍  | 308453/414113 [01:11<00:24, 4398.20it/s]\u001b[A\n",
      " 75%|███████▍  | 308893/414113 [01:11<00:23, 4392.22it/s]\u001b[A\n",
      " 75%|███████▍  | 309333/414113 [01:12<00:24, 4357.02it/s]\u001b[A\n",
      " 75%|███████▍  | 309772/414113 [01:12<00:23, 4366.18it/s]\u001b[A\n",
      " 75%|███████▍  | 310215/414113 [01:12<00:23, 4383.43it/s]\u001b[A\n",
      " 75%|███████▌  | 310654/414113 [01:12<00:23, 4347.38it/s]\u001b[A\n",
      " 75%|███████▌  | 311089/414113 [01:12<00:23, 4345.16it/s]\u001b[A\n",
      " 75%|███████▌  | 311524/414113 [01:12<00:23, 4325.02it/s]\u001b[A\n",
      " 75%|███████▌  | 311959/414113 [01:12<00:23, 4331.37it/s]\u001b[A\n",
      " 75%|███████▌  | 312401/414113 [01:12<00:23, 4355.20it/s]\u001b[A\n",
      " 76%|███████▌  | 312837/414113 [01:12<00:23, 4355.68it/s]\u001b[A\n",
      " 76%|███████▌  | 313276/414113 [01:12<00:23, 4364.18it/s]\u001b[A\n",
      " 76%|███████▌  | 313717/414113 [01:13<00:22, 4376.25it/s]\u001b[A\n",
      " 76%|███████▌  | 314180/414113 [01:13<00:22, 4447.18it/s]\u001b[A\n",
      " 76%|███████▌  | 314640/414113 [01:13<00:22, 4491.16it/s]\u001b[A\n",
      " 76%|███████▌  | 315105/414113 [01:13<00:21, 4535.46it/s]\u001b[A\n",
      " 76%|███████▌  | 315560/414113 [01:13<00:21, 4538.51it/s]\u001b[A\n",
      " 76%|███████▋  | 316027/414113 [01:13<00:21, 4572.05it/s]\u001b[A\n",
      " 76%|███████▋  | 316487/414113 [01:13<00:21, 4579.60it/s]\u001b[A\n",
      " 77%|███████▋  | 316959/414113 [01:13<00:21, 4618.23it/s]\u001b[A\n",
      " 77%|███████▋  | 317422/414113 [01:13<00:21, 4516.79it/s]\u001b[A\n",
      " 77%|███████▋  | 317875/414113 [01:13<00:21, 4486.72it/s]\u001b[A\n",
      " 77%|███████▋  | 318327/414113 [01:14<00:21, 4496.51it/s]\u001b[A\n",
      " 77%|███████▋  | 318780/414113 [01:14<00:21, 4504.52it/s]\u001b[A\n",
      " 77%|███████▋  | 319231/414113 [01:14<00:21, 4458.41it/s]\u001b[A\n",
      " 77%|███████▋  | 319678/414113 [01:14<00:21, 4441.59it/s]\u001b[A\n",
      " 77%|███████▋  | 320123/414113 [01:14<00:21, 4443.47it/s]\u001b[A\n",
      " 77%|███████▋  | 320571/414113 [01:14<00:21, 4454.35it/s]\u001b[A\n",
      " 78%|███████▊  | 321019/414113 [01:14<00:20, 4461.43it/s]\u001b[A\n",
      " 78%|███████▊  | 321467/414113 [01:14<00:20, 4462.61it/s]\u001b[A\n",
      " 78%|███████▊  | 321916/414113 [01:14<00:20, 4468.05it/s]\u001b[A\n",
      " 78%|███████▊  | 322363/414113 [01:14<00:20, 4432.35it/s]\u001b[A\n",
      " 78%|███████▊  | 322807/414113 [01:15<00:20, 4403.63it/s]\u001b[A\n",
      " 78%|███████▊  | 323248/414113 [01:15<00:20, 4403.09it/s]\u001b[A\n",
      " 78%|███████▊  | 323689/414113 [01:15<00:20, 4388.58it/s]\u001b[A\n",
      " 78%|███████▊  | 324128/414113 [01:15<00:20, 4359.66it/s]\u001b[A\n",
      " 78%|███████▊  | 324565/414113 [01:15<00:20, 4334.58it/s]\u001b[A\n",
      " 78%|███████▊  | 325017/414113 [01:15<00:20, 4385.77it/s]\u001b[A\n",
      " 79%|███████▊  | 325456/414113 [01:15<00:20, 4340.89it/s]\u001b[A\n",
      " 79%|███████▊  | 325896/414113 [01:15<00:20, 4356.32it/s]\u001b[A\n",
      " 79%|███████▉  | 326337/414113 [01:15<00:20, 4372.18it/s]\u001b[A\n",
      " 79%|███████▉  | 326775/414113 [01:15<00:19, 4373.45it/s]\u001b[A\n",
      " 79%|███████▉  | 327234/414113 [01:16<00:19, 4434.30it/s]\u001b[A\n",
      " 79%|███████▉  | 327678/414113 [01:16<00:19, 4353.94it/s]\u001b[A\n",
      " 79%|███████▉  | 328129/414113 [01:16<00:19, 4397.74it/s]\u001b[A\n",
      " 79%|███████▉  | 328573/414113 [01:16<00:19, 4407.90it/s]\u001b[A\n",
      " 79%|███████▉  | 329015/414113 [01:16<00:19, 4408.31it/s]\u001b[A\n",
      " 80%|███████▉  | 329457/414113 [01:16<00:19, 4392.92it/s]\u001b[A\n",
      " 80%|███████▉  | 329897/414113 [01:16<00:19, 4313.05it/s]\u001b[A\n",
      " 80%|███████▉  | 330342/414113 [01:16<00:19, 4351.34it/s]\u001b[A\n",
      " 80%|███████▉  | 330783/414113 [01:16<00:19, 4366.97it/s]\u001b[A\n",
      " 80%|███████▉  | 331222/414113 [01:16<00:18, 4371.29it/s]\u001b[A\n",
      " 80%|████████  | 331660/414113 [01:17<00:19, 4288.73it/s]\u001b[A\n",
      " 80%|████████  | 332115/414113 [01:17<00:18, 4362.91it/s]\u001b[A\n",
      " 80%|████████  | 332554/414113 [01:17<00:18, 4370.49it/s]\u001b[A\n",
      " 80%|████████  | 332992/414113 [01:17<00:18, 4348.20it/s]\u001b[A\n",
      " 81%|████████  | 333428/414113 [01:17<00:18, 4346.39it/s]\u001b[A\n",
      " 81%|████████  | 333865/414113 [01:17<00:18, 4351.39it/s]\u001b[A\n",
      " 81%|████████  | 334301/414113 [01:17<00:18, 4287.22it/s]\u001b[A\n",
      " 81%|████████  | 334732/414113 [01:17<00:18, 4291.14it/s]\u001b[A\n",
      " 81%|████████  | 335162/414113 [01:17<00:18, 4238.91it/s]\u001b[A\n",
      " 81%|████████  | 335587/414113 [01:17<00:18, 4187.78it/s]\u001b[A\n",
      " 81%|████████  | 336009/414113 [01:18<00:18, 4196.76it/s]\u001b[A\n",
      " 81%|████████  | 336429/414113 [01:18<00:18, 4191.15it/s]\u001b[A\n",
      " 81%|████████▏ | 336860/414113 [01:18<00:18, 4224.98it/s]\u001b[A\n",
      " 81%|████████▏ | 337292/414113 [01:18<00:18, 4252.96it/s]\u001b[A\n",
      " 82%|████████▏ | 337721/414113 [01:18<00:17, 4262.07it/s]\u001b[A\n",
      " 82%|████████▏ | 338148/414113 [01:18<00:17, 4245.45it/s]\u001b[A\n",
      " 82%|████████▏ | 338578/414113 [01:18<00:17, 4261.28it/s]\u001b[A\n",
      " 82%|████████▏ | 339009/414113 [01:18<00:17, 4275.74it/s]\u001b[A\n",
      " 82%|████████▏ | 339441/414113 [01:18<00:17, 4288.45it/s]\u001b[A\n",
      " 82%|████████▏ | 339876/414113 [01:18<00:17, 4304.18it/s]\u001b[A\n",
      " 82%|████████▏ | 340322/414113 [01:19<00:16, 4348.67it/s]\u001b[A\n",
      " 82%|████████▏ | 340770/414113 [01:19<00:16, 4386.31it/s]\u001b[A\n",
      " 82%|████████▏ | 341209/414113 [01:19<00:16, 4315.09it/s]\u001b[A\n",
      " 83%|████████▎ | 341646/414113 [01:19<00:16, 4331.01it/s]\u001b[A\n",
      " 83%|████████▎ | 342080/414113 [01:19<00:16, 4312.74it/s]\u001b[A\n",
      " 83%|████████▎ | 342528/414113 [01:19<00:16, 4360.29it/s]\u001b[A\n",
      " 83%|████████▎ | 342971/414113 [01:19<00:16, 4380.71it/s]\u001b[A\n",
      " 83%|████████▎ | 343422/414113 [01:19<00:15, 4418.43it/s]\u001b[A\n",
      " 83%|████████▎ | 343867/414113 [01:19<00:15, 4427.19it/s]\u001b[A\n",
      " 83%|████████▎ | 344310/414113 [01:19<00:15, 4387.95it/s]\u001b[A\n",
      " 83%|████████▎ | 344749/414113 [01:20<00:16, 4303.91it/s]\u001b[A\n",
      " 83%|████████▎ | 345184/414113 [01:20<00:15, 4317.63it/s]\u001b[A\n",
      " 83%|████████▎ | 345634/414113 [01:20<00:15, 4370.73it/s]\u001b[A\n",
      " 84%|████████▎ | 346079/414113 [01:20<00:15, 4392.32it/s]\u001b[A\n",
      " 84%|████████▎ | 346533/414113 [01:20<00:15, 4434.89it/s]\u001b[A\n",
      " 84%|████████▍ | 346977/414113 [01:20<00:15, 4384.01it/s]\u001b[A\n",
      " 84%|████████▍ | 347416/414113 [01:20<00:15, 4347.41it/s]\u001b[A\n",
      " 84%|████████▍ | 347852/414113 [01:20<00:15, 4314.94it/s]\u001b[A\n",
      " 84%|████████▍ | 348284/414113 [01:20<00:15, 4189.28it/s]\u001b[A\n",
      " 84%|████████▍ | 348704/414113 [01:21<00:15, 4176.21it/s]\u001b[A\n",
      " 84%|████████▍ | 349142/414113 [01:21<00:15, 4233.21it/s]\u001b[A\n",
      " 84%|████████▍ | 349598/414113 [01:21<00:14, 4324.69it/s]\u001b[A\n",
      " 85%|████████▍ | 350058/414113 [01:21<00:14, 4402.33it/s]\u001b[A\n",
      " 85%|████████▍ | 350511/414113 [01:21<00:14, 4437.63it/s]\u001b[A\n",
      " 85%|████████▍ | 350958/414113 [01:21<00:14, 4445.32it/s]\u001b[A\n",
      " 85%|████████▍ | 351404/414113 [01:21<00:14, 4433.94it/s]\u001b[A\n",
      " 85%|████████▍ | 351848/414113 [01:21<00:14, 4411.29it/s]\u001b[A\n",
      " 85%|████████▌ | 352290/414113 [01:21<00:14, 4368.19it/s]\u001b[A\n",
      " 85%|████████▌ | 352728/414113 [01:21<00:14, 4362.44it/s]\u001b[A\n",
      " 85%|████████▌ | 353165/414113 [01:22<00:13, 4360.40it/s]\u001b[A\n",
      " 85%|████████▌ | 353602/414113 [01:22<00:13, 4351.30it/s]\u001b[A\n",
      " 85%|████████▌ | 354040/414113 [01:22<00:13, 4359.09it/s]\u001b[A\n",
      " 86%|████████▌ | 354499/414113 [01:22<00:13, 4424.60it/s]\u001b[A\n",
      " 86%|████████▌ | 354942/414113 [01:22<00:13, 4406.38it/s]\u001b[A\n",
      " 86%|████████▌ | 355383/414113 [01:22<00:13, 4355.33it/s]\u001b[A\n",
      " 86%|████████▌ | 355819/414113 [01:22<00:13, 4323.56it/s]\u001b[A\n",
      " 86%|████████▌ | 356252/414113 [01:22<00:13, 4321.87it/s]\u001b[A\n",
      " 86%|████████▌ | 356705/414113 [01:22<00:13, 4381.78it/s]\u001b[A\n",
      " 86%|████████▌ | 357144/414113 [01:22<00:13, 4329.43it/s]\u001b[A\n",
      " 86%|████████▋ | 357580/414113 [01:23<00:13, 4336.67it/s]\u001b[A\n",
      " 86%|████████▋ | 358014/414113 [01:23<00:13, 4284.41it/s]\u001b[A\n",
      " 87%|████████▋ | 358450/414113 [01:23<00:12, 4306.18it/s]\u001b[A\n",
      " 87%|████████▋ | 358881/414113 [01:23<00:12, 4303.66it/s]\u001b[A\n",
      " 87%|████████▋ | 359328/414113 [01:23<00:12, 4350.10it/s]\u001b[A\n",
      " 87%|████████▋ | 359764/414113 [01:23<00:12, 4329.15it/s]\u001b[A\n",
      " 87%|████████▋ | 360198/414113 [01:23<00:12, 4300.34it/s]\u001b[A\n",
      " 87%|████████▋ | 360629/414113 [01:23<00:12, 4279.04it/s]\u001b[A\n",
      " 87%|████████▋ | 361058/414113 [01:23<00:12, 4268.78it/s]\u001b[A\n",
      " 87%|████████▋ | 361485/414113 [01:23<00:12, 4250.66it/s]\u001b[A\n",
      " 87%|████████▋ | 361920/414113 [01:24<00:12, 4278.20it/s]\u001b[A\n",
      " 87%|████████▋ | 362348/414113 [01:24<00:12, 4235.94it/s]\u001b[A\n",
      " 88%|████████▊ | 362772/414113 [01:24<00:12, 4196.89it/s]\u001b[A\n",
      " 88%|████████▊ | 363196/414113 [01:24<00:12, 4207.22it/s]\u001b[A\n",
      " 88%|████████▊ | 363617/414113 [01:24<00:12, 4158.93it/s]\u001b[A\n",
      " 88%|████████▊ | 364040/414113 [01:24<00:11, 4177.83it/s]\u001b[A\n",
      " 88%|████████▊ | 364474/414113 [01:24<00:11, 4224.32it/s]\u001b[A\n",
      " 88%|████████▊ | 364900/414113 [01:24<00:11, 4232.37it/s]\u001b[A\n",
      " 88%|████████▊ | 365327/414113 [01:24<00:11, 4240.78it/s]\u001b[A\n",
      " 88%|████████▊ | 365755/414113 [01:24<00:11, 4251.74it/s]\u001b[A\n",
      " 88%|████████▊ | 366198/414113 [01:25<00:11, 4303.03it/s]\u001b[A\n",
      " 89%|████████▊ | 366629/414113 [01:25<00:11, 4293.70it/s]\u001b[A\n",
      " 89%|████████▊ | 367059/414113 [01:25<00:11, 4267.33it/s]\u001b[A\n",
      " 89%|████████▊ | 367486/414113 [01:25<00:10, 4264.35it/s]\u001b[A\n",
      " 89%|████████▉ | 367914/414113 [01:25<00:10, 4268.02it/s]\u001b[A\n",
      " 89%|████████▉ | 368341/414113 [01:25<00:10, 4245.79it/s]\u001b[A\n",
      " 89%|████████▉ | 368766/414113 [01:25<00:10, 4175.67it/s]\u001b[A\n",
      " 89%|████████▉ | 369186/414113 [01:25<00:10, 4180.65it/s]\u001b[A\n",
      " 89%|████████▉ | 369606/414113 [01:25<00:10, 4186.43it/s]\u001b[A\n",
      " 89%|████████▉ | 370031/414113 [01:25<00:10, 4203.65it/s]\u001b[A\n",
      " 89%|████████▉ | 370462/414113 [01:26<00:10, 4232.68it/s]\u001b[A\n",
      " 90%|████████▉ | 370886/414113 [01:26<00:10, 4219.22it/s]\u001b[A\n",
      " 90%|████████▉ | 371325/414113 [01:26<00:10, 4268.47it/s]\u001b[A\n",
      " 90%|████████▉ | 371765/414113 [01:26<00:09, 4305.25it/s]\u001b[A\n",
      " 90%|████████▉ | 372198/414113 [01:26<00:09, 4310.76it/s]\u001b[A\n",
      " 90%|████████▉ | 372630/414113 [01:26<00:09, 4306.74it/s]\u001b[A\n",
      " 90%|█████████ | 373069/414113 [01:26<00:09, 4329.65it/s]\u001b[A\n",
      " 90%|█████████ | 373503/414113 [01:26<00:09, 4288.59it/s]\u001b[A\n",
      " 90%|█████████ | 373933/414113 [01:26<00:09, 4289.10it/s]\u001b[A\n",
      " 90%|█████████ | 374370/414113 [01:26<00:09, 4312.53it/s]\u001b[A\n",
      " 91%|█████████ | 374802/414113 [01:27<00:09, 4299.12it/s]\u001b[A\n",
      " 91%|█████████ | 375232/414113 [01:27<00:09, 4294.54it/s]\u001b[A\n",
      " 91%|█████████ | 375668/414113 [01:27<00:08, 4313.60it/s]\u001b[A\n",
      " 91%|█████████ | 376120/414113 [01:27<00:08, 4371.85it/s]\u001b[A\n",
      " 91%|█████████ | 376576/414113 [01:27<00:08, 4426.32it/s]\u001b[A\n",
      " 91%|█████████ | 377019/414113 [01:27<00:08, 4425.50it/s]\u001b[A\n",
      " 91%|█████████ | 377462/414113 [01:27<00:08, 4418.69it/s]\u001b[A\n",
      " 91%|█████████▏| 377905/414113 [01:27<00:08, 4389.20it/s]\u001b[A\n",
      " 91%|█████████▏| 378345/414113 [01:27<00:08, 4353.89it/s]\u001b[A\n",
      " 91%|█████████▏| 378790/414113 [01:27<00:08, 4381.05it/s]\u001b[A\n",
      " 92%|█████████▏| 379229/414113 [01:28<00:08, 4314.01it/s]\u001b[A\n",
      " 92%|█████████▏| 379661/414113 [01:28<00:08, 4288.95it/s]\u001b[A\n",
      " 92%|█████████▏| 380091/414113 [01:28<00:07, 4280.49it/s]\u001b[A\n",
      " 92%|█████████▏| 380520/414113 [01:28<00:07, 4262.07it/s]\u001b[A\n",
      " 92%|█████████▏| 380971/414113 [01:28<00:07, 4332.62it/s]\u001b[A\n",
      " 92%|█████████▏| 381420/414113 [01:28<00:07, 4377.39it/s]\u001b[A\n",
      " 92%|█████████▏| 381874/414113 [01:28<00:07, 4422.99it/s]\u001b[A\n",
      " 92%|█████████▏| 382317/414113 [01:28<00:07, 4380.98it/s]\u001b[A\n",
      " 92%|█████████▏| 382760/414113 [01:28<00:07, 4394.66it/s]\u001b[A\n",
      " 93%|█████████▎| 383200/414113 [01:29<00:07, 4376.19it/s]\u001b[A\n",
      " 93%|█████████▎| 383645/414113 [01:29<00:06, 4397.84it/s]\u001b[A\n",
      " 93%|█████████▎| 384085/414113 [01:29<00:06, 4366.20it/s]\u001b[A\n",
      " 93%|█████████▎| 384522/414113 [01:29<00:06, 4350.32it/s]\u001b[A\n",
      " 93%|█████████▎| 384958/414113 [01:29<00:06, 4333.93it/s]\u001b[A\n",
      " 93%|█████████▎| 385392/414113 [01:29<00:06, 4334.37it/s]\u001b[A\n",
      " 93%|█████████▎| 385826/414113 [01:29<00:06, 4283.64it/s]\u001b[A\n",
      " 93%|█████████▎| 386255/414113 [01:30<00:15, 1815.07it/s]\u001b[A\n",
      " 93%|█████████▎| 386690/414113 [01:30<00:12, 2199.51it/s]\u001b[A\n",
      " 93%|█████████▎| 387126/414113 [01:30<00:10, 2582.99it/s]\u001b[A\n",
      " 94%|█████████▎| 387563/414113 [01:30<00:09, 2943.14it/s]\u001b[A\n",
      " 94%|█████████▎| 388000/414113 [01:30<00:08, 3262.06it/s]\u001b[A\n",
      " 94%|█████████▍| 388442/414113 [01:30<00:07, 3538.82it/s]\u001b[A\n",
      " 94%|█████████▍| 388891/414113 [01:30<00:06, 3778.71it/s]\u001b[A\n",
      " 94%|█████████▍| 389325/414113 [01:30<00:06, 3929.12it/s]\u001b[A\n",
      " 94%|█████████▍| 389755/414113 [01:30<00:06, 4032.48it/s]\u001b[A\n",
      " 94%|█████████▍| 390185/414113 [01:31<00:05, 4092.34it/s]\u001b[A\n",
      " 94%|█████████▍| 390613/414113 [01:31<00:05, 4126.70it/s]\u001b[A\n",
      " 94%|█████████▍| 391049/414113 [01:31<00:05, 4191.94it/s]\u001b[A\n",
      " 95%|█████████▍| 391495/414113 [01:31<00:05, 4268.13it/s]\u001b[A\n",
      " 95%|█████████▍| 391939/414113 [01:31<00:05, 4318.14it/s]\u001b[A\n",
      " 95%|█████████▍| 392381/414113 [01:31<00:04, 4347.07it/s]\u001b[A\n",
      " 95%|█████████▍| 392820/414113 [01:31<00:04, 4356.93it/s]\u001b[A\n",
      " 95%|█████████▍| 393259/414113 [01:31<00:04, 4336.09it/s]\u001b[A\n",
      " 95%|█████████▌| 393699/414113 [01:31<00:04, 4353.36it/s]\u001b[A\n",
      " 95%|█████████▌| 394136/414113 [01:31<00:04, 4330.32it/s]\u001b[A\n",
      " 95%|█████████▌| 394570/414113 [01:32<00:04, 4264.66it/s]\u001b[A\n",
      " 95%|█████████▌| 394998/414113 [01:32<00:04, 4245.68it/s]\u001b[A\n",
      " 95%|█████████▌| 395424/414113 [01:32<00:04, 4203.25it/s]\u001b[A\n",
      " 96%|█████████▌| 395855/414113 [01:32<00:04, 4233.62it/s]\u001b[A\n",
      " 96%|█████████▌| 396284/414113 [01:32<00:04, 4248.26it/s]\u001b[A\n",
      " 96%|█████████▌| 396719/414113 [01:32<00:04, 4276.16it/s]\u001b[A\n",
      " 96%|█████████▌| 397153/414113 [01:32<00:03, 4292.96it/s]\u001b[A\n",
      " 96%|█████████▌| 397585/414113 [01:32<00:03, 4298.69it/s]\u001b[A\n",
      " 96%|█████████▌| 398016/414113 [01:32<00:03, 4246.83it/s]\u001b[A\n",
      " 96%|█████████▌| 398455/414113 [01:33<00:03, 4287.67it/s]\u001b[A\n",
      " 96%|█████████▋| 398907/414113 [01:33<00:03, 4354.77it/s]\u001b[A\n",
      " 96%|█████████▋| 399350/414113 [01:33<00:03, 4377.03it/s]\u001b[A\n",
      " 97%|█████████▋| 399805/414113 [01:33<00:03, 4425.67it/s]\u001b[A\n",
      " 97%|█████████▋| 400248/414113 [01:33<00:03, 4375.46it/s]\u001b[A\n",
      " 97%|█████████▋| 400686/414113 [01:33<00:03, 4354.21it/s]\u001b[A\n",
      " 97%|█████████▋| 401137/414113 [01:33<00:02, 4397.51it/s]\u001b[A\n",
      " 97%|█████████▋| 401578/414113 [01:33<00:02, 4393.61it/s]\u001b[A\n",
      " 97%|█████████▋| 402021/414113 [01:33<00:02, 4404.17it/s]\u001b[A\n",
      " 97%|█████████▋| 402462/414113 [01:33<00:02, 4354.82it/s]\u001b[A\n",
      " 97%|█████████▋| 402898/414113 [01:34<00:02, 4339.49it/s]\u001b[A\n",
      " 97%|█████████▋| 403342/414113 [01:34<00:02, 4367.78it/s]\u001b[A\n",
      " 98%|█████████▊| 403790/414113 [01:34<00:02, 4398.45it/s]\u001b[A\n",
      " 98%|█████████▊| 404246/414113 [01:34<00:02, 4444.86it/s]\u001b[A\n",
      " 98%|█████████▊| 404692/414113 [01:34<00:02, 4446.97it/s]\u001b[A\n",
      " 98%|█████████▊| 405137/414113 [01:34<00:02, 4436.20it/s]\u001b[A\n",
      " 98%|█████████▊| 405581/414113 [01:34<00:01, 4427.77it/s]\u001b[A\n",
      " 98%|█████████▊| 406024/414113 [01:34<00:01, 4403.69it/s]\u001b[A\n",
      " 98%|█████████▊| 406465/414113 [01:34<00:01, 4386.69it/s]\u001b[A\n",
      " 98%|█████████▊| 406904/414113 [01:34<00:01, 4350.22it/s]\u001b[A\n",
      " 98%|█████████▊| 407340/414113 [01:35<00:01, 4329.96it/s]\u001b[A\n",
      " 98%|█████████▊| 407779/414113 [01:35<00:01, 4346.60it/s]\u001b[A\n",
      " 99%|█████████▊| 408214/414113 [01:35<00:01, 4329.34it/s]\u001b[A\n",
      " 99%|█████████▊| 408648/414113 [01:35<00:01, 4320.74it/s]\u001b[A\n",
      " 99%|█████████▉| 409088/414113 [01:35<00:01, 4343.97it/s]\u001b[A\n",
      " 99%|█████████▉| 409545/414113 [01:35<00:01, 4407.01it/s]\u001b[A\n",
      " 99%|█████████▉| 409988/414113 [01:35<00:00, 4413.77it/s]\u001b[A\n",
      " 99%|█████████▉| 410430/414113 [01:35<00:00, 4388.60it/s]\u001b[A\n",
      " 99%|█████████▉| 410886/414113 [01:35<00:00, 4436.53it/s]\u001b[A\n",
      " 99%|█████████▉| 411330/414113 [01:35<00:00, 4356.06it/s]\u001b[A\n",
      " 99%|█████████▉| 411767/414113 [01:36<00:00, 4335.54it/s]\u001b[A\n",
      "100%|█████████▉| 412201/414113 [01:36<00:00, 4320.26it/s]\u001b[A\n",
      "100%|█████████▉| 412639/414113 [01:36<00:00, 4337.27it/s]\u001b[A\n",
      "100%|█████████▉| 413088/414113 [01:36<00:00, 4380.52it/s]\u001b[A\n",
      "100%|█████████▉| 413530/414113 [01:36<00:00, 4391.39it/s]\u001b[A\n",
      "100%|█████████▉| 413970/414113 [01:36<00:00, 4351.48it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:36<00:00, 4287.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step 41412\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 10          # batch size\n",
    "vocab_threshold = 4        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 256           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, batch_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = optim.Adam(params, lr=0.0001)#momentum 0.9 and 0.999\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)\n",
    "print('total_step', total_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/41412], Loss: 5.1196, Perplexity: 167.2726\n",
      "Epoch [1/3], Step [200/41412], Loss: 4.9309, Perplexity: 138.5004\n",
      "Epoch [1/3], Step [300/41412], Loss: 4.3824, Perplexity: 80.03319\n",
      "Epoch [1/3], Step [400/41412], Loss: 4.5325, Perplexity: 92.99123\n",
      "Epoch [1/3], Step [500/41412], Loss: 4.0178, Perplexity: 55.58153\n",
      "Epoch [1/3], Step [600/41412], Loss: 4.1968, Perplexity: 66.47554\n",
      "Epoch [1/3], Step [700/41412], Loss: 3.5927, Perplexity: 36.33268\n",
      "Epoch [1/3], Step [800/41412], Loss: 4.4508, Perplexity: 85.69507\n",
      "Epoch [1/3], Step [900/41412], Loss: 3.8271, Perplexity: 45.93129\n",
      "Epoch [1/3], Step [1000/41412], Loss: 4.2552, Perplexity: 70.4739\n",
      "Epoch [1/3], Step [1100/41412], Loss: 3.4832, Perplexity: 32.56324\n",
      "Epoch [1/3], Step [1200/41412], Loss: 3.8677, Perplexity: 47.83221\n",
      "Epoch [1/3], Step [1300/41412], Loss: 4.1070, Perplexity: 60.76580\n",
      "Epoch [1/3], Step [1400/41412], Loss: 3.5976, Perplexity: 36.51210\n",
      "Epoch [1/3], Step [1500/41412], Loss: 4.2665, Perplexity: 71.26992\n",
      "Epoch [1/3], Step [1600/41412], Loss: 4.4254, Perplexity: 83.54539\n",
      "Epoch [1/3], Step [1700/41412], Loss: 3.5800, Perplexity: 35.87239\n",
      "Epoch [1/3], Step [1800/41412], Loss: 3.4936, Perplexity: 32.90313\n",
      "Epoch [1/3], Step [1900/41412], Loss: 3.9251, Perplexity: 50.6584\n",
      "Epoch [1/3], Step [2000/41412], Loss: 3.6892, Perplexity: 40.01418\n",
      "Epoch [1/3], Step [2100/41412], Loss: 4.0292, Perplexity: 56.21340\n",
      "Epoch [1/3], Step [2200/41412], Loss: 3.6343, Perplexity: 37.8772\n",
      "Epoch [1/3], Step [2300/41412], Loss: 4.2218, Perplexity: 68.1551\n",
      "Epoch [1/3], Step [2400/41412], Loss: 2.9455, Perplexity: 19.02088\n",
      "Epoch [1/3], Step [2500/41412], Loss: 3.8338, Perplexity: 46.23900\n",
      "Epoch [1/3], Step [2600/41412], Loss: 3.5589, Perplexity: 35.1228\n",
      "Epoch [1/3], Step [2700/41412], Loss: 3.6716, Perplexity: 39.3163\n",
      "Epoch [1/3], Step [2800/41412], Loss: 3.6529, Perplexity: 38.5875\n",
      "Epoch [1/3], Step [2900/41412], Loss: 3.3597, Perplexity: 28.7812\n",
      "Epoch [1/3], Step [3000/41412], Loss: 3.5962, Perplexity: 36.4593\n",
      "Epoch [1/3], Step [3100/41412], Loss: 3.7011, Perplexity: 40.49334\n",
      "Epoch [1/3], Step [3200/41412], Loss: 3.6594, Perplexity: 38.83661\n",
      "Epoch [1/3], Step [3300/41412], Loss: 3.7178, Perplexity: 41.17417\n",
      "Epoch [1/3], Step [3400/41412], Loss: 3.1714, Perplexity: 23.84044\n",
      "Epoch [1/3], Step [3500/41412], Loss: 4.1137, Perplexity: 61.17372\n",
      "Epoch [1/3], Step [3600/41412], Loss: 4.0488, Perplexity: 57.3287\n",
      "Epoch [1/3], Step [3700/41412], Loss: 3.3248, Perplexity: 27.79238\n",
      "Epoch [1/3], Step [3800/41412], Loss: 3.8275, Perplexity: 45.94559\n",
      "Epoch [1/3], Step [3900/41412], Loss: 2.9971, Perplexity: 20.0266\n",
      "Epoch [1/3], Step [4000/41412], Loss: 3.0595, Perplexity: 21.31790\n",
      "Epoch [1/3], Step [4100/41412], Loss: 2.9304, Perplexity: 18.7357\n",
      "Epoch [1/3], Step [4200/41412], Loss: 3.7405, Perplexity: 42.11761\n",
      "Epoch [1/3], Step [4300/41412], Loss: 3.7374, Perplexity: 41.9881\n",
      "Epoch [1/3], Step [4400/41412], Loss: 3.2519, Perplexity: 25.8381\n",
      "Epoch [1/3], Step [4500/41412], Loss: 2.9268, Perplexity: 18.6684\n",
      "Epoch [1/3], Step [4600/41412], Loss: 3.2670, Perplexity: 26.2327\n",
      "Epoch [1/3], Step [4700/41412], Loss: 3.0585, Perplexity: 21.2964\n",
      "Epoch [1/3], Step [4800/41412], Loss: 2.5667, Perplexity: 13.0233\n",
      "Epoch [1/3], Step [4900/41412], Loss: 2.9344, Perplexity: 18.8103\n",
      "Epoch [1/3], Step [5000/41412], Loss: 2.6485, Perplexity: 14.13276\n",
      "Epoch [1/3], Step [5100/41412], Loss: 3.3921, Perplexity: 29.7273\n",
      "Epoch [1/3], Step [5200/41412], Loss: 3.3472, Perplexity: 28.42378\n",
      "Epoch [1/3], Step [5300/41412], Loss: 3.1922, Perplexity: 24.3421\n",
      "Epoch [1/3], Step [5400/41412], Loss: 3.0703, Perplexity: 21.5484\n",
      "Epoch [1/3], Step [5500/41412], Loss: 2.5187, Perplexity: 12.41251\n",
      "Epoch [1/3], Step [5600/41412], Loss: 2.8997, Perplexity: 18.1680\n",
      "Epoch [1/3], Step [5700/41412], Loss: 2.4482, Perplexity: 11.5679\n",
      "Epoch [1/3], Step [5800/41412], Loss: 2.9189, Perplexity: 18.5203\n",
      "Epoch [1/3], Step [5900/41412], Loss: 3.4941, Perplexity: 32.9208\n",
      "Epoch [1/3], Step [6000/41412], Loss: 2.9047, Perplexity: 18.2606\n",
      "Epoch [1/3], Step [6100/41412], Loss: 2.7157, Perplexity: 15.1153\n",
      "Epoch [1/3], Step [6200/41412], Loss: 2.5244, Perplexity: 12.4839\n",
      "Epoch [1/3], Step [6300/41412], Loss: 4.0441, Perplexity: 57.0600\n",
      "Epoch [1/3], Step [6400/41412], Loss: 2.8114, Perplexity: 16.6331\n",
      "Epoch [1/3], Step [6500/41412], Loss: 3.3483, Perplexity: 28.4541\n",
      "Epoch [1/3], Step [6600/41412], Loss: 2.9733, Perplexity: 19.5565\n",
      "Epoch [1/3], Step [6700/41412], Loss: 3.7369, Perplexity: 41.9686\n",
      "Epoch [1/3], Step [6800/41412], Loss: 2.9473, Perplexity: 19.0545\n",
      "Epoch [1/3], Step [6900/41412], Loss: 3.0370, Perplexity: 20.8428\n",
      "Epoch [1/3], Step [7000/41412], Loss: 2.6223, Perplexity: 13.7675\n",
      "Epoch [1/3], Step [7100/41412], Loss: 3.2329, Perplexity: 25.3540\n",
      "Epoch [1/3], Step [7200/41412], Loss: 3.3258, Perplexity: 27.8207\n",
      "Epoch [1/3], Step [7300/41412], Loss: 3.0239, Perplexity: 20.5704\n",
      "Epoch [1/3], Step [7400/41412], Loss: 3.9555, Perplexity: 52.22289\n",
      "Epoch [1/3], Step [7500/41412], Loss: 2.7262, Perplexity: 15.2750\n",
      "Epoch [1/3], Step [7600/41412], Loss: 2.9492, Perplexity: 19.0907\n",
      "Epoch [1/3], Step [7700/41412], Loss: 2.8612, Perplexity: 17.4822\n",
      "Epoch [1/3], Step [7800/41412], Loss: 3.1887, Perplexity: 24.2576\n",
      "Epoch [1/3], Step [7900/41412], Loss: 2.8767, Perplexity: 17.7564\n",
      "Epoch [1/3], Step [8000/41412], Loss: 2.4700, Perplexity: 11.8228\n",
      "Epoch [1/3], Step [8100/41412], Loss: 2.9941, Perplexity: 19.96708\n",
      "Epoch [1/3], Step [8200/41412], Loss: 2.5852, Perplexity: 13.2661\n",
      "Epoch [1/3], Step [8300/41412], Loss: 2.5593, Perplexity: 12.9268\n",
      "Epoch [1/3], Step [8400/41412], Loss: 2.6179, Perplexity: 13.7076\n",
      "Epoch [1/3], Step [8500/41412], Loss: 2.8535, Perplexity: 17.3488\n",
      "Epoch [1/3], Step [8600/41412], Loss: 3.0120, Perplexity: 20.32873\n",
      "Epoch [1/3], Step [8700/41412], Loss: 2.8332, Perplexity: 16.9999\n",
      "Epoch [1/3], Step [8800/41412], Loss: 2.7153, Perplexity: 15.1089\n",
      "Epoch [1/3], Step [8900/41412], Loss: 2.3706, Perplexity: 10.7040\n",
      "Epoch [1/3], Step [9000/41412], Loss: 3.5930, Perplexity: 36.3439\n",
      "Epoch [1/3], Step [9100/41412], Loss: 2.9752, Perplexity: 19.5937\n",
      "Epoch [1/3], Step [9200/41412], Loss: 2.6215, Perplexity: 13.7569\n",
      "Epoch [1/3], Step [9300/41412], Loss: 2.9508, Perplexity: 19.1208\n",
      "Epoch [1/3], Step [9400/41412], Loss: 2.6740, Perplexity: 14.49771\n",
      "Epoch [1/3], Step [9500/41412], Loss: 2.8060, Perplexity: 16.5444\n",
      "Epoch [1/3], Step [9600/41412], Loss: 3.0231, Perplexity: 20.5546\n",
      "Epoch [1/3], Step [9700/41412], Loss: 3.3606, Perplexity: 28.8075\n",
      "Epoch [1/3], Step [9800/41412], Loss: 2.7846, Perplexity: 16.1932\n",
      "Epoch [1/3], Step [9900/41412], Loss: 2.7837, Perplexity: 16.1791\n",
      "Epoch [1/3], Step [10000/41412], Loss: 2.4514, Perplexity: 11.6043\n",
      "Epoch [1/3], Step [10100/41412], Loss: 2.4685, Perplexity: 11.8053\n",
      "Epoch [1/3], Step [10200/41412], Loss: 2.7299, Perplexity: 15.3308\n",
      "Epoch [1/3], Step [10300/41412], Loss: 2.7112, Perplexity: 15.0475\n",
      "Epoch [1/3], Step [10400/41412], Loss: 2.7791, Perplexity: 16.1046\n",
      "Epoch [1/3], Step [10500/41412], Loss: 2.8113, Perplexity: 16.6308\n",
      "Epoch [1/3], Step [10600/41412], Loss: 2.6314, Perplexity: 13.89264\n",
      "Epoch [1/3], Step [10700/41412], Loss: 3.1274, Perplexity: 22.8150\n",
      "Epoch [1/3], Step [10800/41412], Loss: 2.5515, Perplexity: 12.8261\n",
      "Epoch [1/3], Step [10900/41412], Loss: 2.8641, Perplexity: 17.5328\n",
      "Epoch [1/3], Step [11000/41412], Loss: 3.0018, Perplexity: 20.1218\n",
      "Epoch [1/3], Step [11100/41412], Loss: 2.2702, Perplexity: 9.68119\n",
      "Epoch [1/3], Step [11200/41412], Loss: 2.8673, Perplexity: 17.5899\n",
      "Epoch [1/3], Step [11300/41412], Loss: 3.0623, Perplexity: 21.3773\n",
      "Epoch [1/3], Step [11400/41412], Loss: 2.2700, Perplexity: 9.67991\n",
      "Epoch [1/3], Step [11500/41412], Loss: 2.3014, Perplexity: 9.98837\n",
      "Epoch [1/3], Step [11600/41412], Loss: 2.5154, Perplexity: 12.3710\n",
      "Epoch [1/3], Step [11700/41412], Loss: 2.3642, Perplexity: 10.6351\n",
      "Epoch [1/3], Step [11800/41412], Loss: 2.7680, Perplexity: 15.9261\n",
      "Epoch [1/3], Step [11900/41412], Loss: 2.8143, Perplexity: 16.6813\n",
      "Epoch [1/3], Step [12000/41412], Loss: 3.0764, Perplexity: 21.6792\n",
      "Epoch [1/3], Step [12100/41412], Loss: 2.6526, Perplexity: 14.1902\n",
      "Epoch [1/3], Step [12200/41412], Loss: 3.1809, Perplexity: 24.0687\n",
      "Epoch [1/3], Step [12300/41412], Loss: 2.9014, Perplexity: 18.2004\n",
      "Epoch [1/3], Step [12400/41412], Loss: 2.3121, Perplexity: 10.0956\n",
      "Epoch [1/3], Step [12500/41412], Loss: 2.6858, Perplexity: 14.6694\n",
      "Epoch [1/3], Step [12600/41412], Loss: 3.0158, Perplexity: 20.4046\n",
      "Epoch [1/3], Step [12700/41412], Loss: 2.8128, Perplexity: 16.6561\n",
      "Epoch [1/3], Step [12800/41412], Loss: 2.3225, Perplexity: 10.2016\n",
      "Epoch [1/3], Step [12900/41412], Loss: 3.0592, Perplexity: 21.3112\n",
      "Epoch [1/3], Step [13000/41412], Loss: 2.5785, Perplexity: 13.1772\n",
      "Epoch [1/3], Step [13100/41412], Loss: 3.2727, Perplexity: 26.3822\n",
      "Epoch [1/3], Step [13200/41412], Loss: 2.9751, Perplexity: 19.5914\n",
      "Epoch [1/3], Step [13300/41412], Loss: 3.4894, Perplexity: 32.7676\n",
      "Epoch [1/3], Step [13400/41412], Loss: 2.9035, Perplexity: 18.2373\n",
      "Epoch [1/3], Step [13500/41412], Loss: 3.4678, Perplexity: 32.0661\n",
      "Epoch [1/3], Step [13600/41412], Loss: 2.1756, Perplexity: 8.80713\n",
      "Epoch [1/3], Step [13700/41412], Loss: 2.7926, Perplexity: 16.3236\n",
      "Epoch [1/3], Step [13800/41412], Loss: 3.2066, Perplexity: 24.6939\n",
      "Epoch [1/3], Step [13900/41412], Loss: 2.6771, Perplexity: 14.5428\n",
      "Epoch [1/3], Step [14000/41412], Loss: 2.2822, Perplexity: 9.79815\n",
      "Epoch [1/3], Step [14100/41412], Loss: 2.5711, Perplexity: 13.0799\n",
      "Epoch [1/3], Step [14200/41412], Loss: 3.1522, Perplexity: 23.3883\n",
      "Epoch [1/3], Step [14300/41412], Loss: 2.6141, Perplexity: 13.6549\n",
      "Epoch [1/3], Step [14400/41412], Loss: 2.4717, Perplexity: 11.8428\n",
      "Epoch [1/3], Step [14500/41412], Loss: 2.7381, Perplexity: 15.4582\n",
      "Epoch [1/3], Step [14600/41412], Loss: 2.9572, Perplexity: 19.2439\n",
      "Epoch [1/3], Step [14700/41412], Loss: 2.4234, Perplexity: 11.2844\n",
      "Epoch [1/3], Step [14800/41412], Loss: 2.2394, Perplexity: 9.38736\n",
      "Epoch [1/3], Step [14900/41412], Loss: 2.3720, Perplexity: 10.7186\n",
      "Epoch [1/3], Step [15000/41412], Loss: 2.9938, Perplexity: 19.9608\n",
      "Epoch [1/3], Step [15100/41412], Loss: 2.2919, Perplexity: 9.89340\n",
      "Epoch [1/3], Step [15200/41412], Loss: 3.0473, Perplexity: 21.0586\n",
      "Epoch [1/3], Step [15300/41412], Loss: 2.4630, Perplexity: 11.7401\n",
      "Epoch [1/3], Step [15400/41412], Loss: 2.8729, Perplexity: 17.6888\n",
      "Epoch [1/3], Step [15500/41412], Loss: 2.4478, Perplexity: 11.5634\n",
      "Epoch [1/3], Step [15600/41412], Loss: 2.6305, Perplexity: 13.8810\n",
      "Epoch [1/3], Step [15700/41412], Loss: 2.4984, Perplexity: 12.1628\n",
      "Epoch [1/3], Step [15800/41412], Loss: 3.0975, Perplexity: 22.1423\n",
      "Epoch [1/3], Step [15900/41412], Loss: 2.7337, Perplexity: 15.3896\n",
      "Epoch [1/3], Step [16000/41412], Loss: 2.3310, Perplexity: 10.2882\n",
      "Epoch [1/3], Step [16100/41412], Loss: 2.3164, Perplexity: 10.1386\n",
      "Epoch [1/3], Step [16200/41412], Loss: 2.6845, Perplexity: 14.6513\n",
      "Epoch [1/3], Step [16300/41412], Loss: 2.4251, Perplexity: 11.3034\n",
      "Epoch [1/3], Step [16400/41412], Loss: 3.0124, Perplexity: 20.3359\n",
      "Epoch [1/3], Step [16500/41412], Loss: 2.3312, Perplexity: 10.2902\n",
      "Epoch [1/3], Step [16600/41412], Loss: 2.2433, Perplexity: 9.42403\n",
      "Epoch [1/3], Step [16700/41412], Loss: 3.2102, Perplexity: 24.7835\n",
      "Epoch [1/3], Step [16800/41412], Loss: 2.6633, Perplexity: 14.3436\n",
      "Epoch [1/3], Step [16900/41412], Loss: 2.6788, Perplexity: 14.5675\n",
      "Epoch [1/3], Step [17000/41412], Loss: 2.3601, Perplexity: 10.5916\n",
      "Epoch [1/3], Step [17100/41412], Loss: 2.5318, Perplexity: 12.5764\n",
      "Epoch [1/3], Step [17200/41412], Loss: 2.6784, Perplexity: 14.5613\n",
      "Epoch [1/3], Step [17300/41412], Loss: 2.6880, Perplexity: 14.7024\n",
      "Epoch [1/3], Step [17400/41412], Loss: 2.5023, Perplexity: 12.2101\n",
      "Epoch [1/3], Step [17500/41412], Loss: 2.3731, Perplexity: 10.7311\n",
      "Epoch [1/3], Step [17600/41412], Loss: 2.5903, Perplexity: 13.3336\n",
      "Epoch [1/3], Step [17700/41412], Loss: 2.8810, Perplexity: 17.8325\n",
      "Epoch [1/3], Step [17800/41412], Loss: 2.7965, Perplexity: 16.3867\n",
      "Epoch [1/3], Step [17900/41412], Loss: 2.6863, Perplexity: 14.6771\n",
      "Epoch [1/3], Step [18000/41412], Loss: 2.8237, Perplexity: 16.8387\n",
      "Epoch [1/3], Step [18100/41412], Loss: 2.2835, Perplexity: 9.81066\n",
      "Epoch [1/3], Step [18200/41412], Loss: 2.5780, Perplexity: 13.1706\n",
      "Epoch [1/3], Step [18300/41412], Loss: 2.3774, Perplexity: 10.7770\n",
      "Epoch [1/3], Step [18400/41412], Loss: 2.5788, Perplexity: 13.1816\n",
      "Epoch [1/3], Step [18500/41412], Loss: 2.8155, Perplexity: 16.7022\n",
      "Epoch [1/3], Step [18600/41412], Loss: 2.3845, Perplexity: 10.8535\n",
      "Epoch [1/3], Step [18700/41412], Loss: 2.8699, Perplexity: 17.6352\n",
      "Epoch [1/3], Step [18800/41412], Loss: 2.2318, Perplexity: 9.31628\n",
      "Epoch [1/3], Step [18882/41412], Loss: 2.0571, Perplexity: 7.82310"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # reset hidden state of decoder(LSTM)\n",
    "        decoder.hidden = decoder.init_hidden()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
